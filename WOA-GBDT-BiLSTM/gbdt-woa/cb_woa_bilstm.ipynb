{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from catboost import CatBoostRegressor\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/solar_weather copy 2.csv'\n",
    "file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/uae_data_2022.csv'\n",
    "time_step = 24\n",
    "\n",
    "# units = 250\n",
    "# learning_rate = 0.001\n",
    "# dropout_rate = 0.2\n",
    "# batch_size = 64\n",
    "\n",
    "num_feats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dataset (X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    \n",
    "    for i in range(len(X)-time_steps):\n",
    "        v = X[i:i+time_steps, :]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+time_steps])\n",
    "        \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# data = data[(data.index.month.isin([5, 6, 7])) & (data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['GHI', 'temp', 'pressure', 'humidity']]\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# X_scaled, y_scaled = create_dataset(scaled_data, time_step)\n",
    "# print(f'X, y shape {X_scaled.shape} {y_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r2_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    R-squared metric for regression tasks.\n",
    "    \"\"\"\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))  # Residual sum of squares\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))  # Total sum of squares\n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))  # RÂ² formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# # data = data[(data.index.month.isin([6, 7, 8])) & (data.index.year == 2021)]\n",
    "\n",
    "# data = data[(data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['Energy delta[Wh]', 'GHI', 'temp', 'pressure', 'humidity']]\n",
    "# # dataset = data[['Energy delta[Wh]', 'GHI']]\n",
    "\n",
    "# X = dataset.iloc[:, 1:].values  # Features\n",
    "# y = dataset.iloc[:, 0].values   # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# test_size = len(X) - train_size\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "# gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "# # Step 2: Get predictions for all models on both training and test sets\n",
    "# gbdt_output_train = gbdt.predict(X_train)\n",
    "# gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "# gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "# X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "# X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "# X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "# X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "# model = Sequential([\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, epochs=10, batch_size=int(batch_size), validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the objective function\n",
    "# def evaluate_bilstm(hyperparameters):\n",
    "#     # Unpack hyperparameters\n",
    "#     units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "#     print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "#     # Split dataset into training and validation (dummy example)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "#     gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "#     # Step 2: Get predictions for all models on both training and test sets\n",
    "#     gbdt_output_train = gbdt.predict(X_train)\n",
    "#     gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "#     gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "#     X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "#     X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "#     X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "#     X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     model = Sequential([\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "#     # optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     # Train the model\n",
    "#     history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), batch_size=int(batch_size),\n",
    "#                         epochs=5, verbose=1)\n",
    "\n",
    "#     # Return validation loss as fitness\n",
    "#     return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### woa bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/mlsmdgns0kqfybw1r9qm4n5w0000gp/T/ipykernel_50843/3722287823.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n",
    "\n",
    "year = 2022\n",
    "\n",
    "data = data[(data.index.year == year)]\n",
    "\n",
    "# dataset = data[['Temperature', 'DNI', 'DHI', 'GHI', 'Pressure', 'Wind Speed']]\n",
    "dataset = data[['Temperature', 'GHI', 'Pressure', 'Wind Speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the objective function\n",
    "def evaluate_bilstm(hyperparameters):\n",
    "    print(f\"Hyperparameters shape: {np.shape(hyperparameters)}\")\n",
    "\n",
    "    # Ensure 1D format\n",
    "    if isinstance(hyperparameters, np.ndarray) and hyperparameters.ndim > 1:\n",
    "        hyperparameters = hyperparameters[0]\n",
    "    # Unpack hyperparameters\n",
    "    units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "    \n",
    "    print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "    train_size = int(len(dataset)*0.8)\n",
    "    train_dataset, test_dataset = dataset.iloc[:train_size], dataset.iloc[train_size:]\n",
    "\n",
    "    # Split train data to X and y\n",
    "    X_trainy = train_dataset.drop('GHI', axis = 1)\n",
    "    y_trainy = train_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Split test data to X and y\n",
    "    X_testy = test_dataset.drop('GHI', axis = 1)\n",
    "    y_testy = test_dataset.loc[:,['GHI']]\n",
    "\n",
    "    catboost = CatBoostRegressor(n_estimators=100, learning_rate=0.001, depth=5, verbose=0)\n",
    "    catboost.fit(X_trainy, y_trainy)\n",
    "\n",
    "    # Step 2: Get predictions for all models on both training and test sets\n",
    "    cb_output_train = catboost.predict(X_trainy)\n",
    "    cb_output_test = catboost.predict(X_testy)\n",
    "\n",
    "    input_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    output_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    input_scaler.fit(cb_output_train.reshape(-1, 1))\n",
    "    # output_scaler.fit(gbdt_output_train.reshape(-1, 1))\n",
    "    output_scaler.fit(y_trainy)\n",
    "\n",
    "    train_x_norm = input_scaler.transform(cb_output_train.reshape(-1, 1))\n",
    "    test_x_norm = input_scaler.transform(cb_output_test.reshape(-1, 1))\n",
    "    train_y_norm = output_scaler.transform(y_trainy)\n",
    "    test_y_norm = output_scaler.transform(y_testy)\n",
    "    \n",
    "    X_train, y_train = create_dataset(train_x_norm, train_y_norm, time_step)\n",
    "    X_test, y_test = create_dataset(test_x_norm, test_y_norm, time_step)   \n",
    "\n",
    "    # X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "    # X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "      Dropout(dropout_rate),\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "      Dropout(dropout_rate),\n",
    "      Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=int(batch_size), validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Return validation loss as fitness\n",
    "    return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [100, 1e-3, 0.1, 10]  # Lower bounds: [units, learning rate, dropout rate, batch size]\n",
    "ub = [300, 1e-2, 0.4, 300]  # Upper bounds: [units, learning rate, dropout rate, batch size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class WOA:\n",
    "    def __init__(self, obj_func, n_whale, spiral_constant, n_iter,\n",
    "                lb, ub):\n",
    "        \"\"\"\n",
    "        Initialize the Whale Optimization Algorithm (WOA).\n",
    "\n",
    "        Args:\n",
    "            obj_func (callable): Objective function to minimize.\n",
    "            n_whale (int): Number of whales in the population.\n",
    "            spiral_constant (float): Constant for spiral movement.\n",
    "            n_iter (int): Number of iterations.\n",
    "            lb (list): Lower bounds for the search space.\n",
    "            ub (list): Upper bounds for the search space.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.obj_func = obj_func\n",
    "        self.n_whale = n_whale\n",
    "        self.spiral_constant = spiral_constant\n",
    "        self.n_iter = n_iter\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.whale = {}\n",
    "        self.prey = {}\n",
    "\n",
    "    def init_whale(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),)) for i in range(self.n_whale)]\n",
    "        self.whale['position'] = np.array(tmp)\n",
    "        self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "\n",
    "    def init_prey(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),))]\n",
    "        self.prey['position'] = np.array(tmp)\n",
    "        # self.prey['fitness'] = self.obj_func(self.prey['position'])\n",
    "        self.prey['fitness'] = np.array([self.obj_func(self.prey['position'])]) # modified\n",
    "\n",
    "        print('init prey prey fitness', self.prey['fitness'],'\\n')\n",
    "\n",
    "\n",
    "    def update_prey(self):\n",
    "        # if self.whale['fitness'].min() < self.prey['fitness'][0]:\n",
    "        print(\"**** prey updated ****\")\n",
    "        print(self.whale['fitness'])\n",
    "        print(self.prey['position'])\n",
    "        print(self.prey['fitness'])\n",
    "        if self.whale['fitness'].min() < self.prey['fitness'][0]:\n",
    "            self.prey['position'][0] = self.whale['position'][self.whale['fitness'].argmin()]\n",
    "            self.prey['fitness'][0] = self.whale['fitness'].min()\n",
    "\n",
    "\n",
    "    def search(self, idx, A, C):\n",
    "        random_whale = self.whale['position'][np.random.randint(low=0, high=self.n_whale, size=len(idx[0]))]\n",
    "        \n",
    "        d = np.abs(C[..., np.newaxis] * random_whale - self.whale['position'][idx])\n",
    "        \n",
    "        self.whale['position'][idx] = np.clip(random_whale - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def encircle(self, idx, A, C):\n",
    "        d = np.abs(C[..., np.newaxis] * self.prey['position'] - self.whale['position'][idx])\n",
    "        \n",
    "        self.whale['position'][idx] = np.clip(self.prey['position'][0] - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def bubble_net(self, idx):\n",
    "        d_prime = np.abs(self.prey['position'] - self.whale['position'][idx])\n",
    "\n",
    "        l = np.random.uniform(-1, 1, size=len(idx[0]))\n",
    "\n",
    "        spiral_term = np.exp(self.spiral_constant * l)[..., np.newaxis] * np.cos(2 * np.pi * l)[..., np.newaxis]\n",
    "\n",
    "        self.whale[\"position\"][idx] = np.clip(\n",
    "            d_prime * spiral_term + self.prey[\"position\"],\n",
    "            self.lb,\n",
    "            self.ub,\n",
    "        )\n",
    "\n",
    "        # self.whale[\"position\"][idx] = np.clip(\n",
    "        #     d_prime * np.exp(self.spiral_constant * l)[..., np.newaxis] * np.cos(2 * np.pi * l)[..., np.newaxis]\n",
    "        #     + self.prey[\"position\"],\n",
    "        #     self.lb,\n",
    "        #     self.ub,\n",
    "        # )\n",
    "\n",
    "    def optimize(self, a):\n",
    "\n",
    "        p = np.random.random(self.n_whale)\n",
    "        r1 = np.random.random(self.n_whale)\n",
    "        r2 = np.random.random(self.n_whale)\n",
    "        A = 2 * a * r1 - a\n",
    "        C = 2 * r2\n",
    "        search_idx = np.where((p < 0.5) & (abs(A) > 1))\n",
    "        encircle_idx = np.where((p < 0.5) & (abs(A) <= 1))\n",
    "        bubbleNet_idx = np.where(p >= 0.5)\n",
    "        self.search(search_idx, A[search_idx], C[search_idx])\n",
    "        self.encircle(encircle_idx, A[encircle_idx], C[encircle_idx])\n",
    "        self.bubble_net(bubbleNet_idx)\n",
    "        self.whale['fitness'] = self.obj_func(self.whale['position'])\n",
    "        # self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.init_whale()\n",
    "        self.init_prey()\n",
    "        f_values = [self.prey['fitness'][0]]\n",
    "        # f_values = [self.prey['fitness']]\n",
    "        for n in range(self.n_iter):\n",
    "            #print(\"Iteration = \", n, \" f(x) = \", self.prey['fitness'][0])\n",
    "            a = 2 - n * (2 / self.n_iter)\n",
    "            self.optimize(a)\n",
    "            self.update_prey()\n",
    "            # f_values.append(self.prey['fitness'])\n",
    "            f_values.append(self.prey['fitness'][0])\n",
    "        # optimal_x = self.prey['position']\n",
    "        optimal_x = self.prey['position'].flatten()\n",
    "        return f_values, optimal_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters shape: (4,)\n",
      "264.1603307381687 0.0018748202222434625 0.1972628268065506 84.86279163571224\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 5s 248ms/step - loss: 0.1444 - r2_metric: -0.1031 - val_loss: 0.0818 - val_r2_metric: 0.3201\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 2s 311ms/step - loss: 0.0683 - r2_metric: 0.4821 - val_loss: 0.0410 - val_r2_metric: 0.6700\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 2s 314ms/step - loss: 0.0200 - r2_metric: 0.8449 - val_loss: 0.0277 - val_r2_metric: 0.7594\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 2s 324ms/step - loss: 0.0099 - r2_metric: 0.9246 - val_loss: 0.0108 - val_r2_metric: 0.9076\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 2s 314ms/step - loss: 0.0076 - r2_metric: 0.9399 - val_loss: 0.0086 - val_r2_metric: 0.9224\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 2s 340ms/step - loss: 0.0061 - r2_metric: 0.9508 - val_loss: 0.0126 - val_r2_metric: 0.8852\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 3s 383ms/step - loss: 0.0048 - r2_metric: 0.9616 - val_loss: 0.0072 - val_r2_metric: 0.9344\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 2s 320ms/step - loss: 0.0048 - r2_metric: 0.9626 - val_loss: 0.0098 - val_r2_metric: 0.9096\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 2s 329ms/step - loss: 0.0042 - r2_metric: 0.9674 - val_loss: 0.0072 - val_r2_metric: 0.9326\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 2s 336ms/step - loss: 0.0039 - r2_metric: 0.9696 - val_loss: 0.0065 - val_r2_metric: 0.9406\n",
      "Hyperparameters shape: (4,)\n",
      "204.11193966022915 0.006729056788238469 0.21941788770400866 158.7023686637075\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 293ms/step - loss: 0.1687 - r2_metric: -0.2761 - val_loss: 0.1306 - val_r2_metric: -0.0824\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 310ms/step - loss: 0.1130 - r2_metric: 0.1421 - val_loss: 0.0727 - val_r2_metric: 0.3977\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 331ms/step - loss: 0.0700 - r2_metric: 0.4637 - val_loss: 0.0418 - val_r2_metric: 0.6535\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 0.0370 - r2_metric: 0.7260 - val_loss: 0.0160 - val_r2_metric: 0.8677\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 318ms/step - loss: 0.0146 - r2_metric: 0.8906 - val_loss: 0.0274 - val_r2_metric: 0.7727\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 327ms/step - loss: 0.0140 - r2_metric: 0.8947 - val_loss: 0.0184 - val_r2_metric: 0.8477\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 320ms/step - loss: 0.0093 - r2_metric: 0.9313 - val_loss: 0.0135 - val_r2_metric: 0.8881\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.0092 - r2_metric: 0.9274 - val_loss: 0.0082 - val_r2_metric: 0.9323\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 334ms/step - loss: 0.0080 - r2_metric: 0.9352 - val_loss: 0.0097 - val_r2_metric: 0.9193\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 343ms/step - loss: 0.0058 - r2_metric: 0.9539 - val_loss: 0.0150 - val_r2_metric: 0.8757\n",
      "Hyperparameters shape: (4,)\n",
      "195.66407375285422 0.0018468439800111121 0.19903780408883243 44.04988062502702\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 107ms/step - loss: 0.1246 - r2_metric: -0.0311 - val_loss: 0.0696 - val_r2_metric: 0.4192\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0457 - r2_metric: 0.6617 - val_loss: 0.0125 - val_r2_metric: 0.8915\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 152ms/step - loss: 0.0098 - r2_metric: 0.9245 - val_loss: 0.0099 - val_r2_metric: 0.9113\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 136ms/step - loss: 0.0065 - r2_metric: 0.9447 - val_loss: 0.0097 - val_r2_metric: 0.9109\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 136ms/step - loss: 0.0046 - r2_metric: 0.9614 - val_loss: 0.0073 - val_r2_metric: 0.9323\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 136ms/step - loss: 0.0040 - r2_metric: 0.9676 - val_loss: 0.0068 - val_r2_metric: 0.9368\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 140ms/step - loss: 0.0040 - r2_metric: 0.9668 - val_loss: 0.0082 - val_r2_metric: 0.9235\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 134ms/step - loss: 0.0037 - r2_metric: 0.9704 - val_loss: 0.0098 - val_r2_metric: 0.9090\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 2s 138ms/step - loss: 0.0038 - r2_metric: 0.9687 - val_loss: 0.0096 - val_r2_metric: 0.9114\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 2s 137ms/step - loss: 0.0036 - r2_metric: 0.9718 - val_loss: 0.0096 - val_r2_metric: 0.9131\n",
      "Hyperparameters shape: (4,)\n",
      "189.0326210509374 0.004414906855528818 0.13737256156222782 81.18796079508184\n",
      "Epoch 1/10\n",
      "7/7 [==============================] - 3s 158ms/step - loss: 0.1455 - r2_metric: -0.1804 - val_loss: 0.1128 - val_r2_metric: 0.0796\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 126ms/step - loss: 0.0882 - r2_metric: 0.3134 - val_loss: 0.0536 - val_r2_metric: 0.5481\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.0443 - r2_metric: 0.6606 - val_loss: 0.0163 - val_r2_metric: 0.8684\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.0145 - r2_metric: 0.8852 - val_loss: 0.0224 - val_r2_metric: 0.8095\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 207ms/step - loss: 0.0094 - r2_metric: 0.9258 - val_loss: 0.0107 - val_r2_metric: 0.9096\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.0075 - r2_metric: 0.9413 - val_loss: 0.0081 - val_r2_metric: 0.9292\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.0058 - r2_metric: 0.9541 - val_loss: 0.0132 - val_r2_metric: 0.8845\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.0060 - r2_metric: 0.9531 - val_loss: 0.0089 - val_r2_metric: 0.9229\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.0052 - r2_metric: 0.9590 - val_loss: 0.0099 - val_r2_metric: 0.9118\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.0049 - r2_metric: 0.9605 - val_loss: 0.0090 - val_r2_metric: 0.9206\n",
      "Hyperparameters shape: (4,)\n",
      "180.1142719251854 0.008548996057527973 0.12588520419484955 266.8733109088679\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 336ms/step - loss: 0.1960 - r2_metric: -0.3731 - val_loss: 0.1101 - val_r2_metric: 0.0877\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 153ms/step - loss: 0.1200 - r2_metric: 0.0885 - val_loss: 0.1095 - val_r2_metric: 0.0931\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 1s 259ms/step - loss: 0.0984 - r2_metric: 0.2676 - val_loss: 0.0675 - val_r2_metric: 0.4406\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 1s 337ms/step - loss: 0.0735 - r2_metric: 0.4320 - val_loss: 0.0487 - val_r2_metric: 0.5964\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 0.0539 - r2_metric: 0.6006 - val_loss: 0.0343 - val_r2_metric: 0.7158\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 0.0316 - r2_metric: 0.7594 - val_loss: 0.0165 - val_r2_metric: 0.8632\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 0.0147 - r2_metric: 0.8947 - val_loss: 0.0151 - val_r2_metric: 0.8746\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 0.0104 - r2_metric: 0.9169 - val_loss: 0.0258 - val_r2_metric: 0.7860\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 0.0110 - r2_metric: 0.9239 - val_loss: 0.0101 - val_r2_metric: 0.9165\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 1s 322ms/step - loss: 0.0069 - r2_metric: 0.9556 - val_loss: 0.0106 - val_r2_metric: 0.9125\n",
      "Hyperparameters shape: (4,)\n",
      "120.79482631366463 0.006887382248721023 0.3245061846954562 297.0613678881105\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 502ms/step - loss: 0.1975 - r2_metric: -0.5278 - val_loss: 0.1438 - val_r2_metric: -0.1915\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.1494 - r2_metric: -0.1608 - val_loss: 0.1122 - val_r2_metric: 0.0702\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.1264 - r2_metric: 0.0199 - val_loss: 0.1165 - val_r2_metric: 0.0350\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.1181 - r2_metric: 0.0867 - val_loss: 0.1026 - val_r2_metric: 0.1496\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.1026 - r2_metric: 0.2068 - val_loss: 0.0826 - val_r2_metric: 0.3154\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 0.0863 - r2_metric: 0.3342 - val_loss: 0.0683 - val_r2_metric: 0.4340\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 344ms/step - loss: 0.0771 - r2_metric: 0.4036 - val_loss: 0.0563 - val_r2_metric: 0.5339\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 395ms/step - loss: 0.0644 - r2_metric: 0.5022 - val_loss: 0.0449 - val_r2_metric: 0.6276\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.0516 - r2_metric: 0.6038 - val_loss: 0.0364 - val_r2_metric: 0.6987\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 346ms/step - loss: 0.0407 - r2_metric: 0.6844 - val_loss: 0.0260 - val_r2_metric: 0.7848\n",
      "Hyperparameters shape: (4,)\n",
      "193.94984918451 0.002380640243641618 0.22983436456431233 124.34872490061372\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 4s 281ms/step - loss: 0.1489 - r2_metric: -0.1422 - val_loss: 0.1285 - val_r2_metric: -0.0647\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 2s 381ms/step - loss: 0.0940 - r2_metric: 0.2942 - val_loss: 0.0581 - val_r2_metric: 0.5183\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 1s 292ms/step - loss: 0.0564 - r2_metric: 0.5729 - val_loss: 0.0317 - val_r2_metric: 0.7371\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 1s 295ms/step - loss: 0.0207 - r2_metric: 0.8474 - val_loss: 0.0248 - val_r2_metric: 0.7948\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 301ms/step - loss: 0.0153 - r2_metric: 0.8863 - val_loss: 0.0168 - val_r2_metric: 0.8611\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 286ms/step - loss: 0.0101 - r2_metric: 0.9175 - val_loss: 0.0138 - val_r2_metric: 0.8854\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 1s 267ms/step - loss: 0.0095 - r2_metric: 0.9282 - val_loss: 0.0088 - val_r2_metric: 0.9268\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 1s 252ms/step - loss: 0.0072 - r2_metric: 0.9455 - val_loss: 0.0121 - val_r2_metric: 0.9001\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 1s 250ms/step - loss: 0.0069 - r2_metric: 0.9435 - val_loss: 0.0108 - val_r2_metric: 0.9108\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 1s 265ms/step - loss: 0.0064 - r2_metric: 0.9495 - val_loss: 0.0070 - val_r2_metric: 0.9418\n",
      "Hyperparameters shape: (4,)\n",
      "266.84553047076787 0.0085292352546431 0.34333171989978983 138.8363071925087\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 516ms/step - loss: 0.1623 - r2_metric: -0.2254 - val_loss: 0.1145 - val_r2_metric: 0.0514\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 2s 477ms/step - loss: 0.0942 - r2_metric: 0.2590 - val_loss: 0.0624 - val_r2_metric: 0.4831\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 2s 486ms/step - loss: 0.0580 - r2_metric: 0.5473 - val_loss: 0.0385 - val_r2_metric: 0.6812\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 0.0262 - r2_metric: 0.7985 - val_loss: 0.0114 - val_r2_metric: 0.9053\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 2s 485ms/step - loss: 0.0131 - r2_metric: 0.8988 - val_loss: 0.0226 - val_r2_metric: 0.8131\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 2s 511ms/step - loss: 0.0100 - r2_metric: 0.9215 - val_loss: 0.0083 - val_r2_metric: 0.9316\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 0.0081 - r2_metric: 0.9363 - val_loss: 0.0083 - val_r2_metric: 0.9313\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 0.0080 - r2_metric: 0.9370 - val_loss: 0.0113 - val_r2_metric: 0.9061\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 2s 487ms/step - loss: 0.0069 - r2_metric: 0.9461 - val_loss: 0.0109 - val_r2_metric: 0.9098\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 0.0061 - r2_metric: 0.9527 - val_loss: 0.0090 - val_r2_metric: 0.9258\n",
      "Hyperparameters shape: (4,)\n",
      "134.15684102948845 0.0031277154444221728 0.23041740300506705 77.81170276570738\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 107ms/step - loss: 0.1456 - r2_metric: -0.0842 - val_loss: 0.0967 - val_r2_metric: 0.2016\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0721 - r2_metric: 0.4619 - val_loss: 0.0329 - val_r2_metric: 0.7237\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.0246 - r2_metric: 0.8158 - val_loss: 0.0201 - val_r2_metric: 0.8362\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.0132 - r2_metric: 0.8877 - val_loss: 0.0091 - val_r2_metric: 0.9226\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.0096 - r2_metric: 0.9219 - val_loss: 0.0095 - val_r2_metric: 0.9183\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 0.0068 - r2_metric: 0.9498 - val_loss: 0.0116 - val_r2_metric: 0.8992\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.0069 - r2_metric: 0.9485 - val_loss: 0.0087 - val_r2_metric: 0.9246\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 0.0063 - r2_metric: 0.9525 - val_loss: 0.0099 - val_r2_metric: 0.9135\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.0053 - r2_metric: 0.9605 - val_loss: 0.0073 - val_r2_metric: 0.9355\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 0.0054 - r2_metric: 0.9584 - val_loss: 0.0124 - val_r2_metric: 0.8906\n",
      "Hyperparameters shape: (4,)\n",
      "227.69741229655648 0.005582733385471422 0.28541199974073195 111.20940104317663\n",
      "Epoch 1/10\n",
      "5/5 [==============================] - 3s 269ms/step - loss: 0.1478 - r2_metric: -0.1403 - val_loss: 0.1076 - val_r2_metric: -0.1191\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 1s 320ms/step - loss: 0.0825 - r2_metric: 0.3586 - val_loss: 0.0443 - val_r2_metric: 0.6159\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 2s 333ms/step - loss: 0.0365 - r2_metric: 0.7143 - val_loss: 0.0123 - val_r2_metric: 0.7836\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 2s 335ms/step - loss: 0.0140 - r2_metric: 0.8911 - val_loss: 0.0241 - val_r2_metric: 0.3705\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 2s 346ms/step - loss: 0.0093 - r2_metric: 0.9275 - val_loss: 0.0081 - val_r2_metric: 0.7913\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 2s 332ms/step - loss: 0.0087 - r2_metric: 0.9323 - val_loss: 0.0094 - val_r2_metric: 0.7301\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 2s 332ms/step - loss: 0.0069 - r2_metric: 0.9462 - val_loss: 0.0130 - val_r2_metric: 0.6134\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 2s 330ms/step - loss: 0.0062 - r2_metric: 0.9519 - val_loss: 0.0102 - val_r2_metric: 0.6928\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 2s 348ms/step - loss: 0.0060 - r2_metric: 0.9529 - val_loss: 0.0082 - val_r2_metric: 0.7287\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 2s 370ms/step - loss: 0.0060 - r2_metric: 0.9532 - val_loss: 0.0091 - val_r2_metric: 0.6996\n",
      "Hyperparameters shape: (1, 4)\n",
      "257.66119922663023 0.0011523831789607137 0.2512172178859664 205.49956748627028\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 4s 465ms/step - loss: 0.1881 - r2_metric: -0.4146 - val_loss: 0.1117 - val_r2_metric: 0.0744\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 1s 510ms/step - loss: 0.1210 - r2_metric: 0.0735 - val_loss: 0.0971 - val_r2_metric: 0.1950\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 2s 612ms/step - loss: 0.0915 - r2_metric: 0.3041 - val_loss: 0.0657 - val_r2_metric: 0.4556\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 3s 854ms/step - loss: 0.0700 - r2_metric: 0.4600 - val_loss: 0.0444 - val_r2_metric: 0.6324\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 2s 697ms/step - loss: 0.0430 - r2_metric: 0.6729 - val_loss: 0.0308 - val_r2_metric: 0.7447\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 2s 782ms/step - loss: 0.0200 - r2_metric: 0.8462 - val_loss: 0.0152 - val_r2_metric: 0.8739\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 0.0135 - r2_metric: 0.8940 - val_loss: 0.0237 - val_r2_metric: 0.8035\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 0.0114 - r2_metric: 0.9129 - val_loss: 0.0106 - val_r2_metric: 0.9120\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 2s 611ms/step - loss: 0.0086 - r2_metric: 0.9329 - val_loss: 0.0105 - val_r2_metric: 0.9133\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 2s 607ms/step - loss: 0.0086 - r2_metric: 0.9332 - val_loss: 0.0082 - val_r2_metric: 0.9320\n",
      "init prey prey fitness [0.00820291] \n",
      "\n",
      "Hyperparameters shape: (10, 4)\n",
      "264.23640919728825 0.0018832770286592551 0.30580319595954747 300.0\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 4s 918ms/step - loss: 0.1891 - r2_metric: -0.4392 - val_loss: 0.1095 - val_r2_metric: 0.0923\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 2s 896ms/step - loss: 0.1215 - r2_metric: 0.0650 - val_loss: 0.1167 - val_r2_metric: 0.0334\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 2s 887ms/step - loss: 0.1038 - r2_metric: 0.2015 - val_loss: 0.0782 - val_r2_metric: 0.3524\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 2s 998ms/step - loss: 0.0799 - r2_metric: 0.3835 - val_loss: 0.0589 - val_r2_metric: 0.5121\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 2s 918ms/step - loss: 0.0656 - r2_metric: 0.4985 - val_loss: 0.0443 - val_r2_metric: 0.6326\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 2s 966ms/step - loss: 0.0484 - r2_metric: 0.6277 - val_loss: 0.0371 - val_r2_metric: 0.6926\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 2s 907ms/step - loss: 0.0328 - r2_metric: 0.7432 - val_loss: 0.0248 - val_r2_metric: 0.7941\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 2s 909ms/step - loss: 0.0187 - r2_metric: 0.8564 - val_loss: 0.0116 - val_r2_metric: 0.9042\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 0.0112 - r2_metric: 0.9131 - val_loss: 0.0169 - val_r2_metric: 0.8601\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 2s 907ms/step - loss: 0.0129 - r2_metric: 0.8958 - val_loss: 0.0229 - val_r2_metric: 0.8102\n",
      "**** prey updated ****\n",
      "0.022900855168700218\n",
      "[[2.57661199e+02 1.15238318e-03 2.51217218e-01 2.05499567e+02]]\n",
      "[0.00820291]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m woa \u001b[38;5;241m=\u001b[39m WOA(obj_func\u001b[38;5;241m=\u001b[39mobj_func, n_whale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, spiral_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lb\u001b[38;5;241m=\u001b[39mlb, ub\u001b[38;5;241m=\u001b[39mub)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run WOA optimization\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m f_values, optimal_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mwoa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf_values:\u001b[39m\u001b[38;5;124m\"\u001b[39m, f_values)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimal_hyperparameters)\n",
      "Cell \u001b[0;32mIn[35], line 114\u001b[0m, in \u001b[0;36mWOA.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m n \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize(a)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_prey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# f_values.append(self.prey['fitness'])\u001b[39;00m\n\u001b[1;32m    116\u001b[0m f_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[35], line 51\u001b[0m, in \u001b[0;36mWOA.update_prey\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhale\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfitness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39margmin()]\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "# Partial function to adapt objective function for WOA\n",
    "# obj_func = partial(lambda params: [evaluate_bilstm(param) for param in params])\n",
    "\n",
    "# obj_func = lambda params: evaluate_bilstm(params)\n",
    "\n",
    "obj_func = partial(lambda params: evaluate_bilstm(params))\n",
    "\n",
    "# Instantiate WOA\n",
    "woa = WOA(obj_func=obj_func, n_whale=10, spiral_constant=1, n_iter=10, lb=lb, ub=ub)\n",
    "\n",
    "# Run WOA optimization\n",
    "f_values, optimal_hyperparameters = woa.run()\n",
    "print(\"f_values:\", f_values)\n",
    "\n",
    "\n",
    "print(\"Optimal Hyperparameters:\", optimal_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
