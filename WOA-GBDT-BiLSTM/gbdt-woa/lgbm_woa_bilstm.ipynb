{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/solar_weather copy 2.csv'\n",
    "file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/uae_data_2022.csv'\n",
    "time_step = 24\n",
    "\n",
    "# units = 250\n",
    "# learning_rate = 0.001\n",
    "# dropout_rate = 0.2\n",
    "# batch_size = 64\n",
    "\n",
    "num_feats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dataset (X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    \n",
    "    for i in range(len(X)-time_steps):\n",
    "        v = X[i:i+time_steps, :]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+time_steps])\n",
    "        \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# data = data[(data.index.month.isin([5, 6, 7])) & (data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['GHI', 'temp', 'pressure', 'humidity']]\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# X_scaled, y_scaled = create_dataset(scaled_data, time_step)\n",
    "# print(f'X, y shape {X_scaled.shape} {y_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r2_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    R-squared metric for regression tasks.\n",
    "    \"\"\"\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))  # Residual sum of squares\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))  # Total sum of squares\n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))  # RÂ² formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# # data = data[(data.index.month.isin([6, 7, 8])) & (data.index.year == 2021)]\n",
    "\n",
    "# data = data[(data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['Energy delta[Wh]', 'GHI', 'temp', 'pressure', 'humidity']]\n",
    "# # dataset = data[['Energy delta[Wh]', 'GHI']]\n",
    "\n",
    "# X = dataset.iloc[:, 1:].values  # Features\n",
    "# y = dataset.iloc[:, 0].values   # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# test_size = len(X) - train_size\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "# gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "# # Step 2: Get predictions for all models on both training and test sets\n",
    "# gbdt_output_train = gbdt.predict(X_train)\n",
    "# gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "# gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "# X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "# X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "# X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "# X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "# model = Sequential([\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, epochs=10, batch_size=int(batch_size), validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the objective function\n",
    "# def evaluate_bilstm(hyperparameters):\n",
    "#     # Unpack hyperparameters\n",
    "#     units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "#     print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "#     # Split dataset into training and validation (dummy example)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "#     gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "#     # Step 2: Get predictions for all models on both training and test sets\n",
    "#     gbdt_output_train = gbdt.predict(X_train)\n",
    "#     gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "#     gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "#     X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "#     X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "#     X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "#     X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     model = Sequential([\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "#     # optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     # Train the model\n",
    "#     history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), batch_size=int(batch_size),\n",
    "#                         epochs=5, verbose=1)\n",
    "\n",
    "#     # Return validation loss as fitness\n",
    "#     return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### woa bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/mlsmdgns0kqfybw1r9qm4n5w0000gp/T/ipykernel_737/3722287823.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n",
    "\n",
    "year = 2022\n",
    "\n",
    "data = data[(data.index.year == year)]\n",
    "\n",
    "# dataset = data[['Temperature', 'DNI', 'DHI', 'GHI', 'Pressure', 'Wind Speed']]\n",
    "dataset = data[['Temperature', 'GHI', 'Pressure', 'Wind Speed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the objective function\n",
    "def evaluate_bilstm(hyperparameters):\n",
    "    print(f\"Hyperparameters shape: {np.shape(hyperparameters)}\")\n",
    "\n",
    "    # Ensure 1D format\n",
    "    if isinstance(hyperparameters, np.ndarray) and hyperparameters.ndim > 1:\n",
    "        hyperparameters = hyperparameters[0]\n",
    "    # Unpack hyperparameters\n",
    "    units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "    \n",
    "    print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "    train_size = int(len(dataset)*0.8)\n",
    "    train_dataset, test_dataset = dataset.iloc[:train_size], dataset.iloc[train_size:]\n",
    "\n",
    "    # Split train data to X and y\n",
    "    X_trainy = train_dataset.drop('GHI', axis = 1)\n",
    "    y_trainy = train_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Split test data to X and y\n",
    "    X_testy = test_dataset.drop('GHI', axis = 1)\n",
    "    y_testy = test_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Step 1: Train GBDT, XGB, and CatBoost on the training data\n",
    "    lgbm = LGBMRegressor(n_estimators=100, learning_rate=0.001, max_depth=5, verbosity=-1)\n",
    "    lgbm.fit(X_trainy, y_trainy)\n",
    "\n",
    "    # Step 2: Get predictions for all models on both training and test sets\n",
    "    lgbm_output_train = lgbm.predict(X_trainy)\n",
    "    lgbm_output_test = lgbm.predict(X_testy)\n",
    "\n",
    "    input_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    output_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    input_scaler.fit(lgbm_output_train.reshape(-1, 1))\n",
    "    # output_scaler.fit(gbdt_output_train.reshape(-1, 1))\n",
    "    output_scaler.fit(y_trainy)\n",
    "\n",
    "    train_x_norm = input_scaler.transform(lgbm_output_train.reshape(-1, 1))\n",
    "    test_x_norm = input_scaler.transform(lgbm_output_test.reshape(-1, 1))\n",
    "    train_y_norm = output_scaler.transform(y_trainy)\n",
    "    test_y_norm = output_scaler.transform(y_testy)\n",
    "    \n",
    "    X_train, y_train = create_dataset(train_x_norm, train_y_norm, time_step)\n",
    "    X_test, y_test = create_dataset(test_x_norm, test_y_norm, time_step)   \n",
    "\n",
    "    # X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "    # X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "      Dropout(dropout_rate),\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "      Dropout(dropout_rate),\n",
    "      Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=int(batch_size), validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Return validation loss as fitness\n",
    "    return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [100, 1e-3, 0.1, 10]  # Lower bounds: [units, learning rate, dropout rate, batch size]\n",
    "ub = [300, 1e-2, 0.4, 300]  # Upper bounds: [units, learning rate, dropout rate, batch size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class WOA:\n",
    "    def __init__(self, obj_func, n_whale, spiral_constant, n_iter,\n",
    "                lb, ub):\n",
    "        \"\"\"\n",
    "        Initialize the Whale Optimization Algorithm (WOA).\n",
    "\n",
    "        Args:\n",
    "            obj_func (callable): Objective function to minimize.\n",
    "            n_whale (int): Number of whales in the population.\n",
    "            spiral_constant (float): Constant for spiral movement.\n",
    "            n_iter (int): Number of iterations.\n",
    "            lb (list): Lower bounds for the search space.\n",
    "            ub (list): Upper bounds for the search space.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.obj_func = obj_func\n",
    "        self.n_whale = n_whale\n",
    "        self.spiral_constant = spiral_constant\n",
    "        self.n_iter = n_iter\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.whale = {}\n",
    "        self.prey = {}\n",
    "\n",
    "    def init_whale(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),)) for i in range(self.n_whale)]\n",
    "        self.whale['position'] = np.array(tmp)\n",
    "        self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "\n",
    "    def init_prey(self):\n",
    "        self.prey['position'] = np.random.uniform(self.lb, self.ub, size=(len(self.lb),))\n",
    "\n",
    "        # tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),))]\n",
    "        # self.prey['position'] = np.array(tmp)\n",
    "        # self.prey['fitness'] = self.obj_func(self.prey['position'])\n",
    "        # self.prey['fitness'] = [self.obj_func(self.prey['position'])] # modified this by adding [] \n",
    "        self.prey['fitness'] = np.array([self.obj_func(self.prey['position'])]) # modified\n",
    "\n",
    "    # def update_prey(self):\n",
    "    #     # Get the minimum fitness from the whale population\n",
    "    #     min_fitness = min(self.whale['fitness'])  # Find the minimum fitness from whale's fitness array\n",
    "    #     if min_fitness < self.prey['fitness'].item():  # Compare with prey's fitness\n",
    "    #         min_index = np.argmin(self.whale['fitness'])  # Find the index of the minimum fitness\n",
    "    #         self.prey['position'] = self.whale['position'][min_index]  # Update prey's position\n",
    "    #         self.prey['fitness'] = min_fitness  # Update prey's fitness\n",
    "\n",
    "    \n",
    "    # def update_prey(self):\n",
    "\n",
    "    #     if min(self.whale['fitness']) < self.prey['fitness'][0]:\n",
    "    #         self.prey['position'][0] = self.whale['position'][self.whale['fitness'].argmin()]\n",
    "    #         self.prey['fitness'][0] = min(self.whale['fitness'])\n",
    "\n",
    "    def update_prey(self):\n",
    "        # if self.whale['fitness'].min() < self.prey['fitness'][0]:\n",
    "        print(self.whale['fitness'])\n",
    "        print(self.prey['position'])\n",
    "        print(self.prey['fitness'])\n",
    "        if self.whale['fitness'].min() < self.prey['fitness'][0]:\n",
    "            self.prey['position'][0] = self.whale['position'][self.whale['fitness'].argmin()]\n",
    "            self.prey['fitness'][0] = self.whale['fitness'].min()\n",
    "\n",
    "    # def update_prey(self):\n",
    "    #     # Check if whale['fitness'] is a NumPy array or list\n",
    "    #     if isinstance(self.whale['fitness'], (np.ndarray, list)):\n",
    "    #         min_fitness = self.whale['fitness'].min()\n",
    "    #     else:\n",
    "    #         min_fitness = self.whale['fitness']\n",
    "        \n",
    "    #     if min_fitness < self.prey['fitness'][0]:\n",
    "    #         self.prey['position'][0] = self.whale['position'][self.whale['fitness'].argmin()]\n",
    "    #         self.prey['fitness'][0] = min_fitness\n",
    "\n",
    "\n",
    "    def search(self, idx, A, C):\n",
    "        random_whale = self.whale['position'][np.random.randint(low=0, high=self.n_whale, size=len(idx[0]))]\n",
    "        \n",
    "        d = np.abs(C[..., np.newaxis] * random_whale - self.whale['position'][idx])\n",
    "        \n",
    "        self.whale['position'][idx] = np.clip(random_whale - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def encircle(self, idx, A, C):\n",
    "        d = np.abs(C[..., np.newaxis] * self.prey['position'] - self.whale['position'][idx])\n",
    "        \n",
    "        self.whale['position'][idx] = np.clip(self.prey['position'][0] - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def bubble_net(self, idx):\n",
    "        d_prime = np.abs(self.prey['position'] - self.whale['position'][idx])\n",
    "\n",
    "        l = np.random.uniform(-1, 1, size=len(idx[0]))\n",
    "\n",
    "        spiral_term = np.exp(self.spiral_constant * l)[..., np.newaxis] * np.cos(2 * np.pi * l)[..., np.newaxis]\n",
    "\n",
    "        self.whale[\"position\"][idx] = np.clip(\n",
    "            d_prime * spiral_term + self.prey[\"position\"],\n",
    "            self.lb,\n",
    "            self.ub,\n",
    "        )\n",
    "\n",
    "        # self.whale[\"position\"][idx] = np.clip(\n",
    "        #     d_prime * np.exp(self.spiral_constant * l)[..., np.newaxis] * np.cos(2 * np.pi * l)[..., np.newaxis]\n",
    "        #     + self.prey[\"position\"],\n",
    "        #     self.lb,\n",
    "        #     self.ub,\n",
    "        # )\n",
    "\n",
    "    def optimize(self, a):\n",
    "\n",
    "        p = np.random.random(self.n_whale)\n",
    "        r1 = np.random.random(self.n_whale)\n",
    "        r2 = np.random.random(self.n_whale)\n",
    "        A = 2 * a * r1 - a\n",
    "        C = 2 * r2\n",
    "        search_idx = np.where((p < 0.5) & (abs(A) > 1))\n",
    "        encircle_idx = np.where((p < 0.5) & (abs(A) <= 1))\n",
    "        bubbleNet_idx = np.where(p >= 0.5)\n",
    "        self.search(search_idx, A[search_idx], C[search_idx])\n",
    "        self.encircle(encircle_idx, A[encircle_idx], C[encircle_idx])\n",
    "        self.bubble_net(bubbleNet_idx)\n",
    "        self.whale['fitness'] = self.obj_func(self.whale['position'])\n",
    "        # self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.init_whale()\n",
    "        self.init_prey()\n",
    "        f_values = [self.prey['fitness'][0]]\n",
    "        # f_values = [self.prey['fitness']]\n",
    "        for n in range(self.n_iter):\n",
    "            #print(\"Iteration = \", n, \" f(x) = \", self.prey['fitness'][0])\n",
    "            a = 2 - n * (2 / self.n_iter)\n",
    "            self.optimize(a)\n",
    "            self.update_prey()\n",
    "            # f_values.append(self.prey['fitness'])\n",
    "            f_values.append(self.prey['fitness'][0])\n",
    "        # optimal_x = self.prey['position']\n",
    "        optimal_x = self.prey['position'].flatten()\n",
    "        return f_values, optimal_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters shape: (4,)\n",
      "172.29885965360407 0.002137851402415609 0.20130602882254472 254.671942437776\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 236ms/step - loss: 0.1933 - r2_metric: -0.4202 - val_loss: 0.1157 - val_r2_metric: 0.0412\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1265 - r2_metric: 0.0112 - val_loss: 0.1193 - val_r2_metric: 0.0115\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.1087 - r2_metric: 0.1760 - val_loss: 0.0818 - val_r2_metric: 0.3223\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0863 - r2_metric: 0.3423 - val_loss: 0.0653 - val_r2_metric: 0.4587\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0732 - r2_metric: 0.4587 - val_loss: 0.0478 - val_r2_metric: 0.6042\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0485 - r2_metric: 0.6139 - val_loss: 0.0415 - val_r2_metric: 0.6564\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0330 - r2_metric: 0.7650 - val_loss: 0.0132 - val_r2_metric: 0.8907\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0161 - r2_metric: 0.8740 - val_loss: 0.0148 - val_r2_metric: 0.8770\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0141 - r2_metric: 0.8784 - val_loss: 0.0158 - val_r2_metric: 0.8688\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0137 - r2_metric: 0.9036 - val_loss: 0.0094 - val_r2_metric: 0.9224\n",
      "Hyperparameters shape: (4,)\n",
      "292.5853852715537 0.009260981027305694 0.1256433276608108 22.928275055272625\n",
      "Epoch 1/10\n",
      "26/26 [==============================] - 4s 92ms/step - loss: 0.0659 - r2_metric: 0.2636 - val_loss: 0.0167 - val_r2_metric: 0.8705\n",
      "Epoch 2/10\n",
      "26/26 [==============================] - 3s 129ms/step - loss: 0.0155 - r2_metric: -549.1651 - val_loss: 0.0107 - val_r2_metric: 0.8890\n",
      "Epoch 3/10\n",
      "26/26 [==============================] - 3s 134ms/step - loss: 0.0069 - r2_metric: 0.9385 - val_loss: 0.0086 - val_r2_metric: 0.9100\n",
      "Epoch 4/10\n",
      "26/26 [==============================] - 3s 97ms/step - loss: 0.0078 - r2_metric: 0.9374 - val_loss: 0.0064 - val_r2_metric: 0.9343\n",
      "Epoch 5/10\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.0056 - r2_metric: 0.9545 - val_loss: 0.0070 - val_r2_metric: 0.9398\n",
      "Epoch 6/10\n",
      "26/26 [==============================] - 2s 88ms/step - loss: 0.0054 - r2_metric: 0.9565 - val_loss: 0.0099 - val_r2_metric: 0.9059\n",
      "Epoch 7/10\n",
      "26/26 [==============================] - 2s 78ms/step - loss: 0.0055 - r2_metric: 0.9559 - val_loss: 0.0113 - val_r2_metric: 0.8727\n",
      "Epoch 8/10\n",
      "26/26 [==============================] - 3s 100ms/step - loss: 0.0052 - r2_metric: 0.1654 - val_loss: 0.0061 - val_r2_metric: 0.9388\n",
      "Epoch 9/10\n",
      "26/26 [==============================] - 3s 110ms/step - loss: 0.0042 - r2_metric: -254.0870 - val_loss: 0.0111 - val_r2_metric: 0.8853\n",
      "Epoch 10/10\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.0054 - r2_metric: 0.9550 - val_loss: 0.0076 - val_r2_metric: 0.9186\n",
      "Hyperparameters shape: (4,)\n",
      "176.56739594999573 0.0038554730538769336 0.1525791308215551 172.64544905597546\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 3s 211ms/step - loss: 0.1798 - r2_metric: -0.3229 - val_loss: 0.1081 - val_r2_metric: 0.1046\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 0s 102ms/step - loss: 0.1156 - r2_metric: 0.1008 - val_loss: 0.0925 - val_r2_metric: 0.2338\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 0s 105ms/step - loss: 0.0904 - r2_metric: 0.3015 - val_loss: 0.0660 - val_r2_metric: 0.4535\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 0s 99ms/step - loss: 0.0676 - r2_metric: 0.4947 - val_loss: 0.0464 - val_r2_metric: 0.6156\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 0s 100ms/step - loss: 0.0391 - r2_metric: 0.7246 - val_loss: 0.0164 - val_r2_metric: 0.8640\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0169 - r2_metric: 0.8788 - val_loss: 0.0153 - val_r2_metric: 0.8731\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.0122 - r2_metric: 0.9122 - val_loss: 0.0091 - val_r2_metric: 0.9243\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 0s 119ms/step - loss: 0.0096 - r2_metric: 0.9292 - val_loss: 0.0085 - val_r2_metric: 0.9296\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 0s 106ms/step - loss: 0.0089 - r2_metric: 0.9231 - val_loss: 0.0074 - val_r2_metric: 0.9386\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 0s 112ms/step - loss: 0.0082 - r2_metric: 0.9376 - val_loss: 0.0085 - val_r2_metric: 0.9294\n",
      "Hyperparameters shape: (4,)\n",
      "201.78332193797638 0.004572337423054419 0.30679871093838273 165.07417612919474\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 4s 315ms/step - loss: 0.1701 - r2_metric: -0.2586 - val_loss: 0.1253 - val_r2_metric: -0.0384\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 1s 192ms/step - loss: 0.1149 - r2_metric: 0.1425 - val_loss: 0.0813 - val_r2_metric: 0.3260\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 1s 152ms/step - loss: 0.0812 - r2_metric: 0.3854 - val_loss: 0.0522 - val_r2_metric: 0.5679\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 1s 183ms/step - loss: 0.0501 - r2_metric: 0.6310 - val_loss: 0.0286 - val_r2_metric: 0.7631\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0214 - r2_metric: 0.8405 - val_loss: 0.0161 - val_r2_metric: 0.8662\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 1s 146ms/step - loss: 0.0157 - r2_metric: 0.8774 - val_loss: 0.0119 - val_r2_metric: 0.9014\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 1s 172ms/step - loss: 0.0117 - r2_metric: 0.9057 - val_loss: 0.0094 - val_r2_metric: 0.9219\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 1s 219ms/step - loss: 0.0115 - r2_metric: 0.9083 - val_loss: 0.0091 - val_r2_metric: 0.9243\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 1s 132ms/step - loss: 0.0092 - r2_metric: 0.9256 - val_loss: 0.0088 - val_r2_metric: 0.9272\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 1s 145ms/step - loss: 0.0084 - r2_metric: 0.9263 - val_loss: 0.0087 - val_r2_metric: 0.9277\n",
      "Hyperparameters shape: (4,)\n",
      "144.62588506971537 0.007116476182247397 0.15144315844435893 45.2113450099597\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 5s 100ms/step - loss: 0.1338 - r2_metric: -0.0489 - val_loss: 0.0701 - val_r2_metric: 0.4120\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0598 - r2_metric: 0.5572 - val_loss: 0.0179 - val_r2_metric: 0.8476\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0141 - r2_metric: 0.8876 - val_loss: 0.0077 - val_r2_metric: 0.9351\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0095 - r2_metric: 0.9280 - val_loss: 0.0086 - val_r2_metric: 0.9264\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.0083 - r2_metric: 0.9328 - val_loss: 0.0106 - val_r2_metric: 0.9090\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.0075 - r2_metric: 0.9370 - val_loss: 0.0071 - val_r2_metric: 0.9379\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.0069 - r2_metric: 0.9428 - val_loss: 0.0061 - val_r2_metric: 0.9493\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.0059 - r2_metric: 0.9512 - val_loss: 0.0068 - val_r2_metric: 0.9402\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0062 - r2_metric: 0.9520 - val_loss: 0.0069 - val_r2_metric: 0.9398\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.0049 - r2_metric: 0.9613 - val_loss: 0.0066 - val_r2_metric: 0.9424\n",
      "Hyperparameters shape: (4,)\n",
      "186.03046883607763 0.002447246511807539 0.23456332956472603 189.44352040576416\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 291ms/step - loss: 0.1848 - r2_metric: -0.4184 - val_loss: 0.1142 - val_r2_metric: 0.0533\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 175ms/step - loss: 0.1266 - r2_metric: 0.0102 - val_loss: 0.1201 - val_r2_metric: 0.0050\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1031 - r2_metric: 0.2042 - val_loss: 0.0802 - val_r2_metric: 0.3358\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0848 - r2_metric: 0.3439 - val_loss: 0.0645 - val_r2_metric: 0.4654\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 0.0672 - r2_metric: 0.4793 - val_loss: 0.0489 - val_r2_metric: 0.5946\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 0.0461 - r2_metric: 0.6427 - val_loss: 0.0405 - val_r2_metric: 0.6647\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 176ms/step - loss: 0.0292 - r2_metric: 0.7740 - val_loss: 0.0139 - val_r2_metric: 0.8850\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 0.0166 - r2_metric: 0.8709 - val_loss: 0.0112 - val_r2_metric: 0.9072\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 167ms/step - loss: 0.0144 - r2_metric: 0.8879 - val_loss: 0.0142 - val_r2_metric: 0.8821\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0126 - r2_metric: 0.9021 - val_loss: 0.0076 - val_r2_metric: 0.9369\n",
      "Hyperparameters shape: (4,)\n",
      "171.09346841135977 0.0035930536183307643 0.25086619791524933 17.143959473611027\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 4s 56ms/step - loss: 0.0640 - r2_metric: 0.4557 - val_loss: 0.0092 - val_r2_metric: -2284.8735\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 1s 37ms/step - loss: 0.0097 - r2_metric: 0.9194 - val_loss: 0.0079 - val_r2_metric: -1361.1072\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 1s 38ms/step - loss: 0.0073 - r2_metric: 0.9359 - val_loss: 0.0094 - val_r2_metric: -419.9496\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 2s 50ms/step - loss: 0.0075 - r2_metric: 0.9357 - val_loss: 0.0067 - val_r2_metric: -197.3184\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 2s 48ms/step - loss: 0.0059 - r2_metric: 0.9474 - val_loss: 0.0069 - val_r2_metric: -829.7527\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 2s 48ms/step - loss: 0.0065 - r2_metric: 0.9433 - val_loss: 0.0085 - val_r2_metric: -979.8075\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 2s 49ms/step - loss: 0.0075 - r2_metric: 0.9260 - val_loss: 0.0070 - val_r2_metric: -42.7621\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 2s 46ms/step - loss: 0.0062 - r2_metric: 0.9467 - val_loss: 0.0058 - val_r2_metric: -8.2671\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 2s 50ms/step - loss: 0.0050 - r2_metric: 0.9561 - val_loss: 0.0057 - val_r2_metric: -18.0404\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 2s 50ms/step - loss: 0.0046 - r2_metric: 0.9566 - val_loss: 0.0064 - val_r2_metric: -80.1283\n",
      "Hyperparameters shape: (4,)\n",
      "211.62086808626668 0.009144074124798535 0.2632276397758184 23.613671979983426\n",
      "Epoch 1/10\n",
      "24/24 [==============================] - 3s 69ms/step - loss: 0.0856 - r2_metric: 0.3256 - val_loss: 0.0156 - val_r2_metric: -96170.2812\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 1s 48ms/step - loss: 0.0126 - r2_metric: 0.8988 - val_loss: 0.0083 - val_r2_metric: -29943.1660\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 1s 49ms/step - loss: 0.0084 - r2_metric: 0.9275 - val_loss: 0.0080 - val_r2_metric: -41039.7812\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 0.0075 - r2_metric: 0.9358 - val_loss: 0.0070 - val_r2_metric: -32862.4883\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 2s 63ms/step - loss: 0.0066 - r2_metric: 0.9449 - val_loss: 0.0079 - val_r2_metric: -34306.3555\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 0.0057 - r2_metric: 0.9523 - val_loss: 0.0068 - val_r2_metric: -42180.9766\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 2s 104ms/step - loss: 0.0072 - r2_metric: 0.9414 - val_loss: 0.0084 - val_r2_metric: -67327.0859\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 0.0063 - r2_metric: 0.9488 - val_loss: 0.0060 - val_r2_metric: -29432.4785\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 2s 70ms/step - loss: 0.0056 - r2_metric: 0.9553 - val_loss: 0.0106 - val_r2_metric: -33071.9336\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 0.0048 - r2_metric: 0.9584 - val_loss: 0.0078 - val_r2_metric: -32970.8633\n",
      "Hyperparameters shape: (4,)\n",
      "151.57651179425076 0.0028766476675313735 0.11230037447767585 210.33348580621126\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 234ms/step - loss: 0.1886 - r2_metric: -0.4496 - val_loss: 0.1208 - val_r2_metric: -0.0011\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1257 - r2_metric: 0.0289 - val_loss: 0.1252 - val_r2_metric: -0.0376\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.1120 - r2_metric: 0.1371 - val_loss: 0.0878 - val_r2_metric: 0.2722\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0868 - r2_metric: 0.3367 - val_loss: 0.0691 - val_r2_metric: 0.4276\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0738 - r2_metric: 0.4338 - val_loss: 0.0529 - val_r2_metric: 0.5613\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0527 - r2_metric: 0.5989 - val_loss: 0.0405 - val_r2_metric: 0.6646\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0327 - r2_metric: 0.7520 - val_loss: 0.0189 - val_r2_metric: 0.8433\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0160 - r2_metric: 0.8754 - val_loss: 0.0146 - val_r2_metric: 0.8794\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0148 - r2_metric: 0.8803 - val_loss: 0.0184 - val_r2_metric: 0.8479\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0125 - r2_metric: 0.9057 - val_loss: 0.0094 - val_r2_metric: 0.9224\n",
      "Hyperparameters shape: (4,)\n",
      "249.3972001426925 0.0049114741931671054 0.34252794239212647 98.3743582784484\n",
      "Epoch 1/10\n",
      "6/6 [==============================] - 12s 287ms/step - loss: 0.1439 - r2_metric: -0.1040 - val_loss: 0.0911 - val_r2_metric: 0.2581\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 175ms/step - loss: 0.0763 - r2_metric: 0.4105 - val_loss: 0.0426 - val_r2_metric: 0.6455\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 214ms/step - loss: 0.0299 - r2_metric: 0.7723 - val_loss: 0.0097 - val_r2_metric: 0.9268\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 145ms/step - loss: 0.0132 - r2_metric: 0.8992 - val_loss: 0.0089 - val_r2_metric: 0.9266\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 146ms/step - loss: 0.0096 - r2_metric: 0.9267 - val_loss: 0.0072 - val_r2_metric: 0.9465\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 146ms/step - loss: 0.0089 - r2_metric: 0.9303 - val_loss: 0.0076 - val_r2_metric: 0.9348\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 133ms/step - loss: 0.0078 - r2_metric: 0.9411 - val_loss: 0.0070 - val_r2_metric: 0.9425\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 204ms/step - loss: 0.0073 - r2_metric: 0.9428 - val_loss: 0.0073 - val_r2_metric: 0.9427\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 220ms/step - loss: 0.0065 - r2_metric: 0.9498 - val_loss: 0.0072 - val_r2_metric: 0.9429\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 158ms/step - loss: 0.0058 - r2_metric: 0.9545 - val_loss: 0.0072 - val_r2_metric: 0.9409\n",
      "Hyperparameters shape: (4,)\n",
      "136.44970739197692 0.004654324914579578 0.18829581105385917 280.57907275395206\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 537ms/step - loss: 0.1998 - r2_metric: -0.5494 - val_loss: 0.1449 - val_r2_metric: -0.2005\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.1518 - r2_metric: -0.1721 - val_loss: 0.1123 - val_r2_metric: 0.0696\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.1230 - r2_metric: 0.0500 - val_loss: 0.1171 - val_r2_metric: 0.0293\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.1139 - r2_metric: 0.1190 - val_loss: 0.1044 - val_r2_metric: 0.1350\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0987 - r2_metric: 0.2318 - val_loss: 0.0800 - val_r2_metric: 0.3371\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0801 - r2_metric: 0.3811 - val_loss: 0.0639 - val_r2_metric: 0.4702\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.0698 - r2_metric: 0.4596 - val_loss: 0.0503 - val_r2_metric: 0.5831\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.0571 - r2_metric: 0.5578 - val_loss: 0.0369 - val_r2_metric: 0.6940\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.0394 - r2_metric: 0.6941 - val_loss: 0.0265 - val_r2_metric: 0.7804\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.0274 - r2_metric: 0.7882 - val_loss: 0.0127 - val_r2_metric: 0.8946\n",
      "Hyperparameters shape: (10, 4)\n",
      "174.97626050505727 0.0052614408747286324 0.22122713204740455 216.08937278353883\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 2s 290ms/step - loss: 0.1891 - r2_metric: -0.4266 - val_loss: 0.1196 - val_r2_metric: 0.0093\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1260 - r2_metric: 0.0145 - val_loss: 0.1239 - val_r2_metric: -0.0269\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1118 - r2_metric: 0.1504 - val_loss: 0.0869 - val_r2_metric: 0.2796\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0905 - r2_metric: 0.3008 - val_loss: 0.0712 - val_r2_metric: 0.4101\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0761 - r2_metric: 0.4232 - val_loss: 0.0545 - val_r2_metric: 0.5486\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0558 - r2_metric: 0.5674 - val_loss: 0.0405 - val_r2_metric: 0.6646\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 168ms/step - loss: 0.0352 - r2_metric: 0.7390 - val_loss: 0.0160 - val_r2_metric: 0.8676\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0192 - r2_metric: 0.8593 - val_loss: 0.0147 - val_r2_metric: 0.8780\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 0.0164 - r2_metric: 0.8737 - val_loss: 0.0220 - val_r2_metric: 0.8173\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0135 - r2_metric: 0.8954 - val_loss: 0.0086 - val_r2_metric: 0.9285\n",
      "0.008622989989817142\n",
      "[1.36449707e+02 4.65432491e-03 1.88295811e-01 2.80579073e+02]\n",
      "[0.01271707]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m woa \u001b[38;5;241m=\u001b[39m WOA(obj_func\u001b[38;5;241m=\u001b[39mobj_func, n_whale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, spiral_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lb\u001b[38;5;241m=\u001b[39mlb, ub\u001b[38;5;241m=\u001b[39mub)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run WOA optimization\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m f_values, optimal_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mwoa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf_values:\u001b[39m\u001b[38;5;124m\"\u001b[39m, f_values)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimal_hyperparameters)\n",
      "Cell \u001b[0;32mIn[95], line 139\u001b[0m, in \u001b[0;36mWOA.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m n \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize(a)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_prey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# f_values.append(self.prey['fitness'])\u001b[39;00m\n\u001b[1;32m    141\u001b[0m f_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[95], line 65\u001b[0m, in \u001b[0;36mWOA.update_prey\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhale\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfitness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmin\u001b[49m() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39margmin()]\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhale[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'min'"
     ]
    }
   ],
   "source": [
    "# Partial function to adapt objective function for WOA\n",
    "# obj_func = partial(lambda params: [evaluate_bilstm(param) for param in params])\n",
    "\n",
    "# obj_func = lambda params: evaluate_bilstm(params)\n",
    "\n",
    "obj_func = partial(lambda params: evaluate_bilstm(params))\n",
    "\n",
    "# Instantiate WOA\n",
    "woa = WOA(obj_func=obj_func, n_whale=10, spiral_constant=1, n_iter=10, lb=lb, ub=ub)\n",
    "\n",
    "# Run WOA optimization\n",
    "f_values, optimal_hyperparameters = woa.run()\n",
    "print(\"f_values:\", f_values)\n",
    "\n",
    "\n",
    "print(\"Optimal Hyperparameters:\", optimal_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
