{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/solar_weather copy 2.csv'\n",
    "file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/uae_data_2022.csv'\n",
    "time_step = 24\n",
    "\n",
    "# units = 250\n",
    "# learning_rate = 0.001\n",
    "# dropout_rate = 0.2\n",
    "# batch_size = 64\n",
    "\n",
    "num_feats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dataset (X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    \n",
    "    for i in range(len(X)-time_steps):\n",
    "        v = X[i:i+time_steps, :]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+time_steps])\n",
    "        \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# data = data[(data.index.month.isin([5, 6, 7])) & (data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['GHI', 'temp', 'pressure', 'humidity']]\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# X_scaled, y_scaled = create_dataset(scaled_data, time_step)\n",
    "# print(f'X, y shape {X_scaled.shape} {y_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r2_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    R-squared metric for regression tasks.\n",
    "    \"\"\"\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))  # Residual sum of squares\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))  # Total sum of squares\n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))  # RÂ² formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### commented code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# # data = data[(data.index.month.isin([6, 7, 8])) & (data.index.year == 2021)]\n",
    "\n",
    "# data = data[(data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['Energy delta[Wh]', 'GHI', 'temp', 'pressure', 'humidity']]\n",
    "# # dataset = data[['Energy delta[Wh]', 'GHI']]\n",
    "\n",
    "# X = dataset.iloc[:, 1:].values  # Features\n",
    "# y = dataset.iloc[:, 0].values   # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# test_size = len(X) - train_size\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "# gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "# # Step 2: Get predictions for all models on both training and test sets\n",
    "# gbdt_output_train = gbdt.predict(X_train)\n",
    "# gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "# gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "# X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "# X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "# X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "# X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "# model = Sequential([\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, epochs=10, batch_size=int(batch_size), validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the objective function\n",
    "# def evaluate_bilstm(hyperparameters):\n",
    "#     # Unpack hyperparameters\n",
    "#     units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "#     print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "#     # Split dataset into training and validation (dummy example)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "#     gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "#     # Step 2: Get predictions for all models on both training and test sets\n",
    "#     gbdt_output_train = gbdt.predict(X_train)\n",
    "#     gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "#     gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "#     X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "#     X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "#     X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "#     X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     model = Sequential([\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "#     # optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     # Train the model\n",
    "#     history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), batch_size=int(batch_size),\n",
    "#                         epochs=5, verbose=1)\n",
    "\n",
    "#     # Return validation loss as fitness\n",
    "#     return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### woa bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/mlsmdgns0kqfybw1r9qm4n5w0000gp/T/ipykernel_114/3113589644.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n",
    "\n",
    "year = 2022\n",
    "\n",
    "data = data[(data.index.year == year)]\n",
    "\n",
    "# dataset = data[['Temperature', 'DNI', 'DHI', 'GHI', 'Pressure', 'Wind Speed']]\n",
    "dataset = data[['Temperature', 'GHI', 'Pressure', 'Wind Speed']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the objective function\n",
    "def evaluate_bilstm(hyperparameters):\n",
    "    # Unpack hyperparameters\n",
    "    units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "    # hyperparameters = [hyperparameters] if not isinstance(hyperparameters, (list, tuple)) else hyperparameters\n",
    "\n",
    "    # units, learning_rate, dropout_rate, batch_size = (hyperparameters + [None] * 4)[:4]\n",
    "\n",
    "    \n",
    "    # params = {\"units\": units, \"learning_rate\": learning_rate, \"dropout_rate\": dropout_rate, \"batch_size\": batch_size}\n",
    "    # missing_params = [name for name, value in params.items() if value is None]\n",
    "\n",
    "    # if missing_params: \n",
    "    #     raise ValueError(f'Missing required params: {\",\".join(missing_params)}')\n",
    "\n",
    "\n",
    "    print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "    train_size = int(len(dataset)*0.8)\n",
    "    train_dataset, test_dataset = dataset.iloc[:train_size], dataset.iloc[train_size:]\n",
    "\n",
    "    # Split train data to X and y\n",
    "    X_trainy = train_dataset.drop('GHI', axis = 1)\n",
    "    y_trainy = train_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Split test data to X and y\n",
    "    X_testy = test_dataset.drop('GHI', axis = 1)\n",
    "    y_testy = test_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Step 1: Train GBDT, XGB, and CatBoost on the training data\n",
    "    gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=0.001, max_depth=5)\n",
    "\n",
    "    gbdt.fit(X_trainy, y_trainy)\n",
    "\n",
    "    # Step 2: Get predictions for all models on both training and test sets\n",
    "    gbdt_output_train = gbdt.predict(X_trainy)\n",
    "    gbdt_output_test = gbdt.predict(X_testy)\n",
    "\n",
    "    input_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    output_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    input_scaler.fit(gbdt_output_train.reshape(-1, 1))\n",
    "    # output_scaler.fit(gbdt_output_train.reshape(-1, 1))\n",
    "    output_scaler.fit(y_trainy)\n",
    "\n",
    "    train_x_norm = input_scaler.transform(gbdt_output_train.reshape(-1, 1))\n",
    "    test_x_norm = input_scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "    train_y_norm = output_scaler.transform(y_trainy)\n",
    "    test_y_norm = output_scaler.transform(y_testy)\n",
    "    \n",
    "    X_train, y_train = create_dataset(train_x_norm, train_y_norm, time_step)\n",
    "    X_test, y_test = create_dataset(test_x_norm, test_y_norm, time_step)   \n",
    "\n",
    "    # X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "    # X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "      Dropout(dropout_rate),\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "      Dropout(dropout_rate),\n",
    "      Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=int(batch_size), validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    val_r2 = history.history['val_r2_metric'][-1]\n",
    "\n",
    "    # Return validation loss as fitness\n",
    "    return history.history['val_loss'][-1], val_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [100, 1e-3, 0.1, 10]  # Lower bounds: [units, learning rate, dropout rate, batch size]\n",
    "ub = [300, 1e-2, 0.4, 300]  # Upper bounds: [units, learning rate, dropout rate, batch size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "class WOA:\n",
    "    def __init__(self, obj_func, n_whale, spiral_constant, n_iter,\n",
    "                lb, ub):\n",
    "        self.obj_func = obj_func\n",
    "        self.n_whale = n_whale\n",
    "        self.spiral_constant = spiral_constant\n",
    "        self.n_iter = n_iter\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.whale = {}\n",
    "        self.prey = {}\n",
    "\n",
    "        # To store best RÂ² score and the corresponding hyperparameters\n",
    "        self.best_r2 = -np.inf\n",
    "        self.best_hyperparameters = None\n",
    "\n",
    "    def init_whale(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),))\n",
    "               for i in range(self.n_whale)]\n",
    "        self.whale['position'] = np.array(tmp)\n",
    "        self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "    def init_prey(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),))]\n",
    "        self.prey['position'] = np.array(tmp)\n",
    "        self.prey['fitness'] = self.obj_func(self.prey['position'])\n",
    "\n",
    "    def update_prey(self):\n",
    "        if self.whale['fitness'].min() < self.prey['fitness'][0]:\n",
    "            self.prey['position'][0] = self.whale['position'][self.whale['fitness'].argmin()]\n",
    "            self.prey['fitness'][0] = self.whale['fitness'].min()\n",
    "\n",
    "    def search(self, idx, A, C):\n",
    "        random_whale = self.whale['position'][np.random.randint(low=0, high=self.n_whale,\n",
    "                                                                size=len(idx[0]))]\n",
    "        d = np.abs(C[..., np.newaxis] * random_whale - self.whale['position'][idx])\n",
    "        self.whale['position'][idx] = np.clip(random_whale - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def encircle(self, idx, A, C):\n",
    "        d = np.abs(C[..., np.newaxis] * self.prey['position'] - self.whale['position'][idx])\n",
    "        self.whale['position'][idx] = np.clip(self.prey['position'][0] - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def bubble_net(self, idx):\n",
    "        d_prime = np.abs(self.prey['position'] - self.whale['position'][idx])\n",
    "        l = np.random.uniform(-1, 1, size=len(idx[0]))\n",
    "        self.whale[\"position\"][idx] = np.clip(\n",
    "            d_prime * np.exp(self.spiral_constant * l)[..., np.newaxis] * np.cos(2 * np.pi * l)[..., np.newaxis]\n",
    "            + self.prey[\"position\"],\n",
    "            self.lb,\n",
    "            self.ub,\n",
    "        )\n",
    "\n",
    "    def optimize(self, a):\n",
    "\n",
    "        p = np.random.random(self.n_whale)\n",
    "        r1 = np.random.random(self.n_whale)\n",
    "        r2 = np.random.random(self.n_whale)\n",
    "        A = 2 * a * r1 - a\n",
    "        C = 2 * r2\n",
    "        search_idx = np.where((p < 0.5) & (abs(A) > 1))\n",
    "        encircle_idx = np.where((p < 0.5) & (abs(A) <= 1))\n",
    "        bubbleNet_idx = np.where(p >= 0.5)\n",
    "        self.search(search_idx, A[search_idx], C[search_idx])\n",
    "        self.encircle(encircle_idx, A[encircle_idx], C[encircle_idx])\n",
    "        self.bubble_net(bubbleNet_idx)\n",
    "        self.whale['fitness'] = self.obj_func(self.whale['position'])\n",
    "\n",
    "    def run(self):\n",
    "        self.init_whale()\n",
    "        self.init_prey()\n",
    "        f_values = [self.prey['fitness'][0]]\n",
    "        for n in range(self.n_iter):\n",
    "            #print(\"Iteration = \", n, \" f(x) = \", self.prey['fitness'][0])\n",
    "            a = 2 - n * (2 / self.n_iter)\n",
    "            self.optimize(a)\n",
    "            self.update_prey()\n",
    "            \n",
    "            # Check RÂ² score for the current iteration\n",
    "            r2_value = self.obj_func(self.prey['position'])  # Get the RÂ² value (or use any other metric)\n",
    "            \n",
    "            # Update best RÂ² and store the hyperparameters\n",
    "            if r2_value > self.best_r2:\n",
    "                self.best_r2 = r2_value\n",
    "                self.best_hyperparameters = self.prey['position'][0]  # Save the hyperparameters associated with best RÂ² score\n",
    "                \n",
    "            f_values.append(self.prey['fitness'][0])\n",
    "        optimal_x = self.prey['position'].squeeze()\n",
    "        # return f_values, optimal_x\n",
    "        return f_values, self.best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.3628863441614 0.001381924456033926 0.3150996377032167 239.6825951614175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 9s 970ms/step - loss: 0.1853 - r2_metric: -0.3759 - val_loss: 0.1097 - val_r2_metric: 0.0913\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 1s 389ms/step - loss: 0.1220 - r2_metric: 0.0526 - val_loss: 0.1078 - val_r2_metric: 0.1065\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 1s 402ms/step - loss: 0.0998 - r2_metric: 0.2509 - val_loss: 0.0755 - val_r2_metric: 0.3744\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 1s 462ms/step - loss: 0.0811 - r2_metric: 0.3784 - val_loss: 0.0584 - val_r2_metric: 0.5157\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 1s 464ms/step - loss: 0.0611 - r2_metric: 0.5394 - val_loss: 0.0454 - val_r2_metric: 0.6236\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 1s 495ms/step - loss: 0.0427 - r2_metric: 0.7000 - val_loss: 0.0264 - val_r2_metric: 0.7811\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 2s 494ms/step - loss: 0.0224 - r2_metric: 0.8318 - val_loss: 0.0116 - val_r2_metric: 0.9035\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 1s 449ms/step - loss: 0.0107 - r2_metric: 0.9214 - val_loss: 0.0237 - val_r2_metric: 0.8037\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 2s 512ms/step - loss: 0.0147 - r2_metric: 0.8970 - val_loss: 0.0188 - val_r2_metric: 0.8439\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 1s 492ms/step - loss: 0.0107 - r2_metric: 0.9230 - val_loss: 0.0109 - val_r2_metric: 0.9098\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 1s 420ms/step - loss: 0.0075 - r2_metric: 0.9394 - val_loss: 0.0115 - val_r2_metric: 0.9047\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 1s 325ms/step - loss: 0.0081 - r2_metric: 0.9356 - val_loss: 0.0112 - val_r2_metric: 0.9071\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.0077 - r2_metric: 0.9431 - val_loss: 0.0100 - val_r2_metric: 0.9175\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 1s 333ms/step - loss: 0.0062 - r2_metric: 0.9527 - val_loss: 0.0106 - val_r2_metric: 0.9121\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 0.0057 - r2_metric: 0.9593 - val_loss: 0.0114 - val_r2_metric: 0.9057\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 1s 341ms/step - loss: 0.0059 - r2_metric: 0.9520 - val_loss: 0.0110 - val_r2_metric: 0.9086\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 1s 411ms/step - loss: 0.0057 - r2_metric: 0.9531 - val_loss: 0.0102 - val_r2_metric: 0.9152\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 1s 360ms/step - loss: 0.0054 - r2_metric: 0.9593 - val_loss: 0.0104 - val_r2_metric: 0.9138\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 1s 453ms/step - loss: 0.0052 - r2_metric: 0.9568 - val_loss: 0.0107 - val_r2_metric: 0.9114\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 1s 465ms/step - loss: 0.0065 - r2_metric: 0.9473 - val_loss: 0.0105 - val_r2_metric: 0.9126\n",
      "101.80033758590778 0.004734493449631718 0.10270301928239448 240.94369883676396\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 250ms/step - loss: 0.2040 - r2_metric: -0.5326 - val_loss: 0.1481 - val_r2_metric: -0.2275\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.1512 - r2_metric: -0.1617 - val_loss: 0.1130 - val_r2_metric: 0.0639\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.1208 - r2_metric: 0.0654 - val_loss: 0.1249 - val_r2_metric: -0.0350\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 1s 144ms/step - loss: 0.1189 - r2_metric: 0.0611 - val_loss: 0.0968 - val_r2_metric: 0.1978\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.0975 - r2_metric: 0.2526 - val_loss: 0.0798 - val_r2_metric: 0.3384\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.0883 - r2_metric: 0.3223 - val_loss: 0.0701 - val_r2_metric: 0.4188\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0780 - r2_metric: 0.4215 - val_loss: 0.0549 - val_r2_metric: 0.5454\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 0.0599 - r2_metric: 0.5653 - val_loss: 0.0415 - val_r2_metric: 0.6563\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0398 - r2_metric: 0.6959 - val_loss: 0.0272 - val_r2_metric: 0.7750\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0223 - r2_metric: 0.8343 - val_loss: 0.0172 - val_r2_metric: 0.8571\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.0175 - r2_metric: 0.8569 - val_loss: 0.0246 - val_r2_metric: 0.7958\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0166 - r2_metric: 0.8742 - val_loss: 0.0180 - val_r2_metric: 0.8505\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.0112 - r2_metric: 0.9146 - val_loss: 0.0129 - val_r2_metric: 0.8931\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 0s 183ms/step - loss: 0.0097 - r2_metric: 0.9285 - val_loss: 0.0113 - val_r2_metric: 0.9065\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0091 - r2_metric: 0.9294 - val_loss: 0.0114 - val_r2_metric: 0.9055\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 1s 301ms/step - loss: 0.0075 - r2_metric: 0.9440 - val_loss: 0.0095 - val_r2_metric: 0.9212\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 0.0065 - r2_metric: 0.9496 - val_loss: 0.0112 - val_r2_metric: 0.9069\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 0.0057 - r2_metric: 0.9515 - val_loss: 0.0126 - val_r2_metric: 0.8957\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0057 - r2_metric: 0.9568 - val_loss: 0.0121 - val_r2_metric: 0.8994\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 0.0051 - r2_metric: 0.9612 - val_loss: 0.0108 - val_r2_metric: 0.9109\n",
      "101.75531845859895 0.00624826235281646 0.2791741013208502 243.01624306284054\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 6s 558ms/step - loss: 0.1927 - r2_metric: -0.4136 - val_loss: 0.1328 - val_r2_metric: -0.1004\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.1370 - r2_metric: -0.0352 - val_loss: 0.1138 - val_r2_metric: 0.0570\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 0.1201 - r2_metric: 0.0545 - val_loss: 0.1042 - val_r2_metric: 0.1368\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 0.1003 - r2_metric: 0.1868 - val_loss: 0.0785 - val_r2_metric: 0.3497\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 0.0840 - r2_metric: 0.3487 - val_loss: 0.0664 - val_r2_metric: 0.4496\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 1s 260ms/step - loss: 0.0735 - r2_metric: 0.4527 - val_loss: 0.0493 - val_r2_metric: 0.5919\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 1s 287ms/step - loss: 0.0544 - r2_metric: 0.5698 - val_loss: 0.0361 - val_r2_metric: 0.7011\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 0.0352 - r2_metric: 0.7324 - val_loss: 0.0170 - val_r2_metric: 0.8592\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 0.0185 - r2_metric: 0.8498 - val_loss: 0.0226 - val_r2_metric: 0.8126\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 0.0160 - r2_metric: 0.8754 - val_loss: 0.0248 - val_r2_metric: 0.7945\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 1s 271ms/step - loss: 0.0151 - r2_metric: 0.8889 - val_loss: 0.0159 - val_r2_metric: 0.8685\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 1s 152ms/step - loss: 0.0097 - r2_metric: 0.9249 - val_loss: 0.0135 - val_r2_metric: 0.8877\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 0.0111 - r2_metric: 0.9140 - val_loss: 0.0109 - val_r2_metric: 0.9098\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 0.0092 - r2_metric: 0.9245 - val_loss: 0.0113 - val_r2_metric: 0.9066\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.0087 - r2_metric: 0.9326 - val_loss: 0.0096 - val_r2_metric: 0.9204\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 0.0072 - r2_metric: 0.9443 - val_loss: 0.0106 - val_r2_metric: 0.9120\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 1s 250ms/step - loss: 0.0069 - r2_metric: 0.9477 - val_loss: 0.0119 - val_r2_metric: 0.9016\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 1s 154ms/step - loss: 0.0072 - r2_metric: 0.9435 - val_loss: 0.0131 - val_r2_metric: 0.8913\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 1s 303ms/step - loss: 0.0075 - r2_metric: 0.9429 - val_loss: 0.0129 - val_r2_metric: 0.8933\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 0.0068 - r2_metric: 0.9494 - val_loss: 0.0120 - val_r2_metric: 0.9009\n",
      "168.99904089988388 0.00612547977501531 0.1391907413294134 87.38755027395419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 9s 337ms/step - loss: 0.1503 - r2_metric: -0.1430 - val_loss: 0.1250 - val_r2_metric: -0.1213\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 2s 241ms/step - loss: 0.0922 - r2_metric: 0.2926 - val_loss: 0.0531 - val_r2_metric: 0.5581\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 2s 231ms/step - loss: 0.0436 - r2_metric: 0.6877 - val_loss: 0.0125 - val_r2_metric: 0.8846\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 2s 218ms/step - loss: 0.0144 - r2_metric: 0.8890 - val_loss: 0.0137 - val_r2_metric: 0.8526\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 2s 240ms/step - loss: 0.0091 - r2_metric: 0.9248 - val_loss: 0.0120 - val_r2_metric: 0.8753\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 2s 241ms/step - loss: 0.0073 - r2_metric: 0.9435 - val_loss: 0.0098 - val_r2_metric: 0.8980\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 2s 304ms/step - loss: 0.0055 - r2_metric: 0.9560 - val_loss: 0.0122 - val_r2_metric: 0.8651\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 2s 285ms/step - loss: 0.0050 - r2_metric: 0.9584 - val_loss: 0.0097 - val_r2_metric: 0.8971\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 2s 230ms/step - loss: 0.0048 - r2_metric: 0.9650 - val_loss: 0.0098 - val_r2_metric: 0.8948\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.0047 - r2_metric: 0.9654 - val_loss: 0.0119 - val_r2_metric: 0.8710\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 1s 209ms/step - loss: 0.0041 - r2_metric: 0.9690 - val_loss: 0.0104 - val_r2_metric: 0.8865\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 1s 173ms/step - loss: 0.0048 - r2_metric: 0.9620 - val_loss: 0.0099 - val_r2_metric: 0.8908\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 1s 123ms/step - loss: 0.0040 - r2_metric: 0.9682 - val_loss: 0.0129 - val_r2_metric: 0.8655\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 1s 150ms/step - loss: 0.0045 - r2_metric: 0.9649 - val_loss: 0.0084 - val_r2_metric: 0.9120\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 1s 167ms/step - loss: 0.0044 - r2_metric: 0.9658 - val_loss: 0.0100 - val_r2_metric: 0.8901\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.0042 - r2_metric: 0.9671 - val_loss: 0.0103 - val_r2_metric: 0.8935\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 1s 180ms/step - loss: 0.0041 - r2_metric: 0.9670 - val_loss: 0.0100 - val_r2_metric: 0.8942\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 2s 248ms/step - loss: 0.0038 - r2_metric: 0.9703 - val_loss: 0.0093 - val_r2_metric: 0.8986\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 2s 268ms/step - loss: 0.0036 - r2_metric: 0.9721 - val_loss: 0.0091 - val_r2_metric: 0.9027\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 2s 238ms/step - loss: 0.0034 - r2_metric: 0.9735 - val_loss: 0.0096 - val_r2_metric: 0.9005\n",
      "241.69662998252085 0.009061699573544631 0.390325328645027 232.96318931028623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 8s 1s/step - loss: 0.1879 - r2_metric: -0.3810 - val_loss: 0.1118 - val_r2_metric: 0.0736\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 0.1246 - r2_metric: 0.0314 - val_loss: 0.0982 - val_r2_metric: 0.1864\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 2s 615ms/step - loss: 0.0977 - r2_metric: 0.2575 - val_loss: 0.0749 - val_r2_metric: 0.3794\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 2s 820ms/step - loss: 0.0801 - r2_metric: 0.3832 - val_loss: 0.0546 - val_r2_metric: 0.5474\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 2s 749ms/step - loss: 0.0565 - r2_metric: 0.5802 - val_loss: 0.0418 - val_r2_metric: 0.6537\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 2s 697ms/step - loss: 0.0354 - r2_metric: 0.7222 - val_loss: 0.0178 - val_r2_metric: 0.8525\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.0185 - r2_metric: 0.8620 - val_loss: 0.0119 - val_r2_metric: 0.9012\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 2s 740ms/step - loss: 0.0107 - r2_metric: 0.9095 - val_loss: 0.0167 - val_r2_metric: 0.8612\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 2s 780ms/step - loss: 0.0121 - r2_metric: 0.9061 - val_loss: 0.0111 - val_r2_metric: 0.9076\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 2s 679ms/step - loss: 0.0083 - r2_metric: 0.9358 - val_loss: 0.0084 - val_r2_metric: 0.9303\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 3s 772ms/step - loss: 0.0073 - r2_metric: 0.9434 - val_loss: 0.0091 - val_r2_metric: 0.9243\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 2s 726ms/step - loss: 0.0069 - r2_metric: 0.9461 - val_loss: 0.0101 - val_r2_metric: 0.9164\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 2s 677ms/step - loss: 0.0069 - r2_metric: 0.9509 - val_loss: 0.0104 - val_r2_metric: 0.9138\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 2s 714ms/step - loss: 0.0058 - r2_metric: 0.9566 - val_loss: 0.0093 - val_r2_metric: 0.9226\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 2s 696ms/step - loss: 0.0058 - r2_metric: 0.9518 - val_loss: 0.0087 - val_r2_metric: 0.9279\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 2s 728ms/step - loss: 0.0054 - r2_metric: 0.9567 - val_loss: 0.0084 - val_r2_metric: 0.9300\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 2s 645ms/step - loss: 0.0053 - r2_metric: 0.9594 - val_loss: 0.0098 - val_r2_metric: 0.9186\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 2s 608ms/step - loss: 0.0051 - r2_metric: 0.9606 - val_loss: 0.0101 - val_r2_metric: 0.9161\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 2s 521ms/step - loss: 0.0053 - r2_metric: 0.9595 - val_loss: 0.0102 - val_r2_metric: 0.9158\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 1s 432ms/step - loss: 0.0046 - r2_metric: 0.9662 - val_loss: 0.0094 - val_r2_metric: 0.9220\n",
      "159.10199764856313 0.0018052066860918146 0.11549316585253096 116.46822502885006\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 267ms/step - loss: 0.1517 - r2_metric: -0.1694 - val_loss: 0.1254 - val_r2_metric: -2174902.5000\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 1s 211ms/step - loss: 0.1001 - r2_metric: 0.2290 - val_loss: 0.0672 - val_r2_metric: -525846.3125\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 1s 212ms/step - loss: 0.0704 - r2_metric: 0.4546 - val_loss: 0.0409 - val_r2_metric: -207814.2969\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 2s 412ms/step - loss: 0.0342 - r2_metric: 0.7369 - val_loss: 0.0231 - val_r2_metric: -98336.9609\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 2s 391ms/step - loss: 0.0139 - r2_metric: 0.8938 - val_loss: 0.0202 - val_r2_metric: -46150.1797\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 1s 214ms/step - loss: 0.0103 - r2_metric: 0.9195 - val_loss: 0.0114 - val_r2_metric: -17136.7754\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 1s 254ms/step - loss: 0.0071 - r2_metric: 0.9444 - val_loss: 0.0119 - val_r2_metric: -29404.2617\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.0068 - r2_metric: 0.9473 - val_loss: 0.0094 - val_r2_metric: -10354.0898\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0057 - r2_metric: 0.9554 - val_loss: 0.0121 - val_r2_metric: -14385.3428\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 1s 201ms/step - loss: 0.0052 - r2_metric: 0.9590 - val_loss: 0.0112 - val_r2_metric: -8334.0293\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 1s 193ms/step - loss: 0.0049 - r2_metric: 0.9613 - val_loss: 0.0091 - val_r2_metric: -9703.7754\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0046 - r2_metric: 0.9641 - val_loss: 0.0103 - val_r2_metric: -20060.9082\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 1s 172ms/step - loss: 0.0041 - r2_metric: 0.9683 - val_loss: 0.0113 - val_r2_metric: -21786.3164\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 1s 188ms/step - loss: 0.0042 - r2_metric: 0.9675 - val_loss: 0.0107 - val_r2_metric: -13964.0059\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 1s 238ms/step - loss: 0.0038 - r2_metric: 0.9695 - val_loss: 0.0099 - val_r2_metric: -11597.6260\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 1s 207ms/step - loss: 0.0039 - r2_metric: 0.9698 - val_loss: 0.0104 - val_r2_metric: -26403.3359\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0037 - r2_metric: 0.9709 - val_loss: 0.0109 - val_r2_metric: -23342.3906\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 1s 206ms/step - loss: 0.0037 - r2_metric: 0.9711 - val_loss: 0.0097 - val_r2_metric: -21805.2617\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.0035 - r2_metric: 0.9721 - val_loss: 0.0118 - val_r2_metric: -11928.4629\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 1s 222ms/step - loss: 0.0038 - r2_metric: 0.9698 - val_loss: 0.0102 - val_r2_metric: -21382.0801\n",
      "289.3207829141777 0.0037593108282931325 0.2655958412648638 176.1342485241717\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 8s 866ms/step - loss: 0.1704 - r2_metric: -0.2414 - val_loss: 0.1107 - val_r2_metric: 0.0826\n",
      "Epoch 2/20\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.1027 - r2_metric: 0.2146 - val_loss: 0.0699 - val_r2_metric: 0.4208\n",
      "Epoch 3/20\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.0744 - r2_metric: 0.4718 - val_loss: 0.0430 - val_r2_metric: 0.6438\n",
      "Epoch 4/20\n",
      "4/4 [==============================] - 2s 633ms/step - loss: 0.0390 - r2_metric: 0.7302 - val_loss: 0.0300 - val_r2_metric: 0.7512\n",
      "Epoch 5/20\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0156 - r2_metric: 0.8778 - val_loss: 0.0166 - val_r2_metric: 0.8621\n",
      "Epoch 6/20\n",
      "4/4 [==============================] - 3s 609ms/step - loss: 0.0119 - r2_metric: 0.9081 - val_loss: 0.0099 - val_r2_metric: 0.9177\n",
      "Epoch 7/20\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0087 - r2_metric: 0.9313 - val_loss: 0.0099 - val_r2_metric: 0.9177\n",
      "Epoch 8/20\n",
      "4/4 [==============================] - 3s 611ms/step - loss: 0.0077 - r2_metric: 0.9260 - val_loss: 0.0141 - val_r2_metric: 0.8830\n",
      "Epoch 9/20\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0071 - r2_metric: 0.9438 - val_loss: 0.0099 - val_r2_metric: 0.9177\n",
      "Epoch 10/20\n",
      "4/4 [==============================] - 2s 446ms/step - loss: 0.0063 - r2_metric: 0.9504 - val_loss: 0.0105 - val_r2_metric: 0.9127\n",
      "Epoch 11/20\n",
      "4/4 [==============================] - 1s 340ms/step - loss: 0.0056 - r2_metric: 0.9400 - val_loss: 0.0118 - val_r2_metric: 0.9023\n",
      "Epoch 12/20\n",
      "4/4 [==============================] - 1s 307ms/step - loss: 0.0057 - r2_metric: 0.9584 - val_loss: 0.0110 - val_r2_metric: 0.9088\n",
      "Epoch 13/20\n",
      "4/4 [==============================] - 1s 344ms/step - loss: 0.0051 - r2_metric: 0.9588 - val_loss: 0.0099 - val_r2_metric: 0.9184\n",
      "Epoch 14/20\n",
      "4/4 [==============================] - 1s 348ms/step - loss: 0.0051 - r2_metric: 0.9644 - val_loss: 0.0106 - val_r2_metric: 0.9118\n",
      "Epoch 15/20\n",
      "4/4 [==============================] - 1s 359ms/step - loss: 0.0050 - r2_metric: 0.9630 - val_loss: 0.0120 - val_r2_metric: 0.9005\n",
      "Epoch 16/20\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 0.0047 - r2_metric: 0.9582 - val_loss: 0.0106 - val_r2_metric: 0.9121\n",
      "Epoch 17/20\n",
      "4/4 [==============================] - 2s 392ms/step - loss: 0.0042 - r2_metric: 0.9683 - val_loss: 0.0093 - val_r2_metric: 0.9233\n",
      "Epoch 18/20\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.0050 - r2_metric: 0.9656 - val_loss: 0.0096 - val_r2_metric: 0.9202\n",
      "Epoch 19/20\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0044 - r2_metric: 0.9650 - val_loss: 0.0146 - val_r2_metric: 0.8787\n",
      "Epoch 20/20\n",
      "4/4 [==============================] - 2s 409ms/step - loss: 0.0048 - r2_metric: 0.9610 - val_loss: 0.0097 - val_r2_metric: 0.9196\n",
      "164.7373003257537 0.002179486712272665 0.12277759765244202 244.32798627022527\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 320ms/step - loss: 0.1880 - r2_metric: -0.3550 - val_loss: 0.1104 - val_r2_metric: 0.0852\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 0.1175 - r2_metric: 0.1106 - val_loss: 0.1088 - val_r2_metric: 0.0980\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 1s 177ms/step - loss: 0.0982 - r2_metric: 0.2643 - val_loss: 0.0689 - val_r2_metric: 0.4289\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 0.0702 - r2_metric: 0.4665 - val_loss: 0.0473 - val_r2_metric: 0.6078\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.0500 - r2_metric: 0.6345 - val_loss: 0.0267 - val_r2_metric: 0.7790\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 0.0256 - r2_metric: 0.8196 - val_loss: 0.0162 - val_r2_metric: 0.8661\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 0.0131 - r2_metric: 0.8892 - val_loss: 0.0279 - val_r2_metric: 0.7686\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 1s 163ms/step - loss: 0.0139 - r2_metric: 0.8955 - val_loss: 0.0169 - val_r2_metric: 0.8601\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 1s 148ms/step - loss: 0.0087 - r2_metric: 0.9313 - val_loss: 0.0095 - val_r2_metric: 0.9215\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 0.0080 - r2_metric: 0.9363 - val_loss: 0.0097 - val_r2_metric: 0.9197\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 0.0071 - r2_metric: 0.9449 - val_loss: 0.0106 - val_r2_metric: 0.9122\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 0.0060 - r2_metric: 0.9545 - val_loss: 0.0100 - val_r2_metric: 0.9173\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 0.0050 - r2_metric: 0.9571 - val_loss: 0.0113 - val_r2_metric: 0.9062\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 1s 169ms/step - loss: 0.0054 - r2_metric: 0.9559 - val_loss: 0.0114 - val_r2_metric: 0.9053\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 0.0049 - r2_metric: 0.9606 - val_loss: 0.0094 - val_r2_metric: 0.9224\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 1s 149ms/step - loss: 0.0044 - r2_metric: 0.9645 - val_loss: 0.0091 - val_r2_metric: 0.9242\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 1s 156ms/step - loss: 0.0045 - r2_metric: 0.9670 - val_loss: 0.0101 - val_r2_metric: 0.9160\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 0.0045 - r2_metric: 0.9684 - val_loss: 0.0102 - val_r2_metric: 0.9158\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 1s 165ms/step - loss: 0.0048 - r2_metric: 0.9583 - val_loss: 0.0101 - val_r2_metric: 0.9164\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.0041 - r2_metric: 0.9704 - val_loss: 0.0103 - val_r2_metric: 0.9143\n",
      "105.58603234284642 0.00234666970393662 0.3339220925669867 286.8788814180694\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 452ms/step - loss: 0.2047 - r2_metric: -0.5830 - val_loss: 0.1588 - val_r2_metric: -0.3161\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.1664 - r2_metric: -0.2816 - val_loss: 0.1259 - val_r2_metric: -0.0431\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.1341 - r2_metric: -0.0360 - val_loss: 0.1143 - val_r2_metric: 0.0532\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.1213 - r2_metric: 0.0608 - val_loss: 0.1175 - val_r2_metric: 0.0266\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 269ms/step - loss: 0.1161 - r2_metric: 0.0936 - val_loss: 0.1017 - val_r2_metric: 0.1574\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.1012 - r2_metric: 0.2137 - val_loss: 0.0852 - val_r2_metric: 0.2941\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.0890 - r2_metric: 0.3124 - val_loss: 0.0736 - val_r2_metric: 0.3900\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.0804 - r2_metric: 0.3783 - val_loss: 0.0642 - val_r2_metric: 0.4684\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.0721 - r2_metric: 0.4425 - val_loss: 0.0546 - val_r2_metric: 0.5475\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 207ms/step - loss: 0.0618 - r2_metric: 0.5226 - val_loss: 0.0452 - val_r2_metric: 0.6255\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.0479 - r2_metric: 0.6300 - val_loss: 0.0361 - val_r2_metric: 0.7008\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.0386 - r2_metric: 0.7027 - val_loss: 0.0263 - val_r2_metric: 0.7817\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 0.0268 - r2_metric: 0.7933 - val_loss: 0.0162 - val_r2_metric: 0.8659\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0196 - r2_metric: 0.8484 - val_loss: 0.0108 - val_r2_metric: 0.9107\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.0142 - r2_metric: 0.8904 - val_loss: 0.0126 - val_r2_metric: 0.8959\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0133 - r2_metric: 0.8974 - val_loss: 0.0171 - val_r2_metric: 0.8587\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.0166 - r2_metric: 0.8694 - val_loss: 0.0137 - val_r2_metric: 0.8865\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.0122 - r2_metric: 0.9053 - val_loss: 0.0107 - val_r2_metric: 0.9110\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.0106 - r2_metric: 0.9161 - val_loss: 0.0092 - val_r2_metric: 0.9235\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.0096 - r2_metric: 0.9253 - val_loss: 0.0095 - val_r2_metric: 0.9217\n",
      "190.07650456424022 0.0015618544130169697 0.2965180918695305 281.98028898910206\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 767ms/step - loss: 0.2003 - r2_metric: -0.5468 - val_loss: 0.1344 - val_r2_metric: -0.1139\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 490ms/step - loss: 0.1380 - r2_metric: -0.0669 - val_loss: 0.1112 - val_r2_metric: 0.0790\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 389ms/step - loss: 0.1149 - r2_metric: 0.1113 - val_loss: 0.1120 - val_r2_metric: 0.0718\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 0.1037 - r2_metric: 0.1910 - val_loss: 0.0817 - val_r2_metric: 0.3233\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 0.0849 - r2_metric: 0.3457 - val_loss: 0.0669 - val_r2_metric: 0.4460\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 0.0730 - r2_metric: 0.4354 - val_loss: 0.0554 - val_r2_metric: 0.5412\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 447ms/step - loss: 0.0603 - r2_metric: 0.5349 - val_loss: 0.0432 - val_r2_metric: 0.6420\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0462 - r2_metric: 0.6421 - val_loss: 0.0333 - val_r2_metric: 0.7238\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 345ms/step - loss: 0.0330 - r2_metric: 0.7455 - val_loss: 0.0241 - val_r2_metric: 0.8003\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 0.0187 - r2_metric: 0.8534 - val_loss: 0.0113 - val_r2_metric: 0.9064\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 362ms/step - loss: 0.0113 - r2_metric: 0.9126 - val_loss: 0.0139 - val_r2_metric: 0.8850\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 411ms/step - loss: 0.0126 - r2_metric: 0.9004 - val_loss: 0.0216 - val_r2_metric: 0.8207\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 437ms/step - loss: 0.0154 - r2_metric: 0.8813 - val_loss: 0.0152 - val_r2_metric: 0.8740\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 385ms/step - loss: 0.0100 - r2_metric: 0.9226 - val_loss: 0.0109 - val_r2_metric: 0.9095\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 0.0085 - r2_metric: 0.9333 - val_loss: 0.0086 - val_r2_metric: 0.9291\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 329ms/step - loss: 0.0072 - r2_metric: 0.9443 - val_loss: 0.0108 - val_r2_metric: 0.9105\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 352ms/step - loss: 0.0081 - r2_metric: 0.9372 - val_loss: 0.0107 - val_r2_metric: 0.9114\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 354ms/step - loss: 0.0071 - r2_metric: 0.9448 - val_loss: 0.0096 - val_r2_metric: 0.9204\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 375ms/step - loss: 0.0073 - r2_metric: 0.9436 - val_loss: 0.0099 - val_r2_metric: 0.9179\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 324ms/step - loss: 0.0063 - r2_metric: 0.9513 - val_loss: 0.0105 - val_r2_metric: 0.9126\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m woa \u001b[38;5;241m=\u001b[39m WOA(obj_func\u001b[38;5;241m=\u001b[39mobj_func, n_whale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, spiral_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, lb\u001b[38;5;241m=\u001b[39mlb, ub\u001b[38;5;241m=\u001b[39mub)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run WOA optimization\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m f_values, optimal_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mwoa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimal_hyperparameters)\n",
      "Cell \u001b[0;32mIn[11], line 71\u001b[0m, in \u001b[0;36mWOA.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_whale()\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_prey\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     f_values \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter):\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;66;03m#print(\"Iteration = \", n, \" f(x) = \", self.prey['fitness'][0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 27\u001b[0m, in \u001b[0;36mWOA.init_prey\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m tmp \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlb, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mub, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlb),))]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(tmp)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mposition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Partial function to adapt objective function for WOA\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# obj_func = partial(lambda params: [evaluate_bilstm(param) for param in params])\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# obj_func = lambda params: evaluate_bilstm(params)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m obj_func \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28;01mlambda\u001b[39;00m params: \u001b[43mevaluate_bilstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Instantiate WOA\u001b[39;00m\n\u001b[1;32m      9\u001b[0m woa \u001b[38;5;241m=\u001b[39m WOA(obj_func\u001b[38;5;241m=\u001b[39mobj_func, n_whale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, spiral_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, lb\u001b[38;5;241m=\u001b[39mlb, ub\u001b[38;5;241m=\u001b[39mub)\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mevaluate_bilstm\u001b[0;34m(hyperparameters)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_bilstm\u001b[39m(hyperparameters):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Unpack hyperparameters\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     units, learning_rate, dropout_rate, batch_size \u001b[38;5;241m=\u001b[39m hyperparameters\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# hyperparameters = [hyperparameters] if not isinstance(hyperparameters, (list, tuple)) else hyperparameters\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# units, learning_rate, dropout_rate, batch_size = (hyperparameters + [None] * 4)[:4]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# if missing_params: \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#     raise ValueError(f'Missing required params: {\",\".join(missing_params)}')\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(units, learning_rate, dropout_rate, batch_size)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 1)"
     ]
    }
   ],
   "source": [
    "# Partial function to adapt objective function for WOA\n",
    "# obj_func = partial(lambda params: [evaluate_bilstm(param) for param in params])\n",
    "\n",
    "# obj_func = lambda params: evaluate_bilstm(params)\n",
    "\n",
    "obj_func = partial(lambda params: evaluate_bilstm(params))\n",
    "\n",
    "# Instantiate WOA\n",
    "woa = WOA(obj_func=obj_func, n_whale=10, spiral_constant=1, n_iter=20, lb=lb, ub=ub)\n",
    "\n",
    "# Run WOA optimization\n",
    "f_values, optimal_hyperparameters = woa.run()\n",
    "\n",
    "print(\"Optimal Hyperparameters:\", optimal_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
