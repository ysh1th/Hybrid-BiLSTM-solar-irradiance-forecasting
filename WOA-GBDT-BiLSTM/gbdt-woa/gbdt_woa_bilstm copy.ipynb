{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "from functools import partial \n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/solar_weather copy 2.csv'\n",
    "file_dir = '/Users/yashwanthkaruparthi/Documents/Acads/sem7/design project/execution/data/uae_data_2022.csv'\n",
    "time_step = 24\n",
    "\n",
    "# units = 250\n",
    "# learning_rate = 0.001\n",
    "# dropout_rate = 0.2\n",
    "# batch_size = 64\n",
    "\n",
    "num_feats = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dataset (X, y, time_steps = 1):\n",
    "    Xs, ys = [], []\n",
    "    \n",
    "    for i in range(len(X)-time_steps):\n",
    "        v = X[i:i+time_steps, :]\n",
    "        Xs.append(v)\n",
    "        ys.append(y[i+time_steps])\n",
    "        \n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# data = data[(data.index.month.isin([5, 6, 7])) & (data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['GHI', 'temp', 'pressure', 'humidity']]\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(dataset)\n",
    "\n",
    "# X_scaled, y_scaled = create_dataset(scaled_data, time_step)\n",
    "# print(f'X, y shape {X_scaled.shape} {y_scaled.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r2_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    R-squared metric for regression tasks.\n",
    "    \"\"\"\n",
    "    ss_res = K.sum(K.square(y_true - y_pred))  # Residual sum of squares\n",
    "    ss_tot = K.sum(K.square(y_true - K.mean(y_true)))  # Total sum of squares\n",
    "    return 1 - (ss_res / (ss_tot + K.epsilon()))  # RÂ² formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unwanted code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Time'], index_col=['Time'])\n",
    "\n",
    "# # data = data[(data.index.month.isin([6, 7, 8])) & (data.index.year == 2021)]\n",
    "\n",
    "# data = data[(data.index.year == 2021)]\n",
    "\n",
    "# dataset = data[['Energy delta[Wh]', 'GHI', 'temp', 'pressure', 'humidity']]\n",
    "# # dataset = data[['Energy delta[Wh]', 'GHI']]\n",
    "\n",
    "# X = dataset.iloc[:, 1:].values  # Features\n",
    "# y = dataset.iloc[:, 0].values   # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# test_size = len(X) - train_size\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "# gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "# # Step 2: Get predictions for all models on both training and test sets\n",
    "# gbdt_output_train = gbdt.predict(X_train)\n",
    "# gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "# gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "# X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "# X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "# X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "# X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "# model = Sequential([\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#   Dropout(dropout_rate),\n",
    "#   Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, epochs=10, batch_size=int(batch_size), validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Define the objective function\n",
    "# def evaluate_bilstm(hyperparameters):\n",
    "#     # Unpack hyperparameters\n",
    "#     units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "#     print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "#     # Split dataset into training and validation (dummy example)\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#     gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=learning_rate, max_depth=5)\n",
    "\n",
    "#     gbdt.fit(X_train, y_train.ravel())\n",
    "\n",
    "#     # Step 2: Get predictions for all models on both training and test sets\n",
    "#     gbdt_output_train = gbdt.predict(X_train)\n",
    "#     gbdt_output_test = gbdt.predict(X_test)\n",
    "\n",
    "#     scaler = MinMaxScaler()\n",
    "#     gbdt_output_train_scaled = scaler.fit_transform(gbdt_output_train.reshape(-1, 1))\n",
    "#     gbdt_output_test_scaled = scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "\n",
    "#     X_train_bilstm_gbdt, y_train_bilstm_gbdt = create_dataset(gbdt_output_train_scaled, time_step)\n",
    "#     X_test_bilstm_gbdt, y_test_bilstm_gbdt = create_dataset(gbdt_output_test_scaled, time_step)\n",
    "\n",
    "#     X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "#     X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "\n",
    "#     # Build the BiLSTM model\n",
    "#     model = Sequential([\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#         Dropout(dropout_rate),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "\n",
    "#     # model = Sequential([\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "#     #     Dropout(dropout_rate),\n",
    "#     #     Dense(1)\n",
    "#     # ])\n",
    "#     # optimizer = Adam(learning_rate=learning_rate)\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#     # Train the model\n",
    "#     history = model.fit(X_train_bilstm_gbdt, y_train_bilstm_gbdt, validation_data=(X_test_bilstm_gbdt, y_test_bilstm_gbdt), batch_size=int(batch_size),\n",
    "#                         epochs=5, verbose=1)\n",
    "\n",
    "#     # Return validation loss as fitness\n",
    "#     return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### woa bilstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/mlsmdgns0kqfybw1r9qm4n5w0000gp/T/ipykernel_25938/3113589644.py:1: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(file_dir, header=0, infer_datetime_format=True, parse_dates=['Datetime'], index_col=['Datetime'])\n",
    "\n",
    "year = 2022\n",
    "\n",
    "data = data[(data.index.year == year)]\n",
    "\n",
    "# dataset = data[['Temperature', 'DNI', 'DHI', 'GHI', 'Pressure', 'Wind Speed']]\n",
    "dataset = data[['Temperature', 'GHI', 'Pressure', 'Wind Speed']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the objective function\n",
    "def evaluate_bilstm(hyperparameters):\n",
    "    # Unpack hyperparameters\n",
    "    if isinstance(hyperparameters, np.ndarray) and hyperparameters.ndim > 1:\n",
    "      hyperparameters = hyperparameters[0]\n",
    "\n",
    "    units, learning_rate, dropout_rate, batch_size = hyperparameters\n",
    "    # hyperparameters = [hyperparameters] if not isinstance(hyperparameters, (list, tuple)) else hyperparameters\n",
    "\n",
    "    # units, learning_rate, dropout_rate, batch_size = (hyperparameters + [None] * 4)[:4]\n",
    "\n",
    "    \n",
    "    # params = {\"units\": units, \"learning_rate\": learning_rate, \"dropout_rate\": dropout_rate, \"batch_size\": batch_size}\n",
    "    # missing_params = [name for name, value in params.items() if value is None]\n",
    "\n",
    "    # if missing_params: \n",
    "    #     raise ValueError(f'Missing required params: {\",\".join(missing_params)}')\n",
    "\n",
    "\n",
    "    print(units, learning_rate, dropout_rate, batch_size)\n",
    "\n",
    "\n",
    "    train_size = int(len(dataset)*0.8)\n",
    "    train_dataset, test_dataset = dataset.iloc[:train_size], dataset.iloc[train_size:]\n",
    "\n",
    "    # Split train data to X and y\n",
    "    X_trainy = train_dataset.drop('GHI', axis = 1)\n",
    "    y_trainy = train_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Split test data to X and y\n",
    "    X_testy = test_dataset.drop('GHI', axis = 1)\n",
    "    y_testy = test_dataset.loc[:,['GHI']]\n",
    "\n",
    "    # Step 1: Train GBDT, XGB, and CatBoost on the training data\n",
    "    gbdt = GradientBoostingRegressor(n_estimators=100, learning_rate=0.001, max_depth=5)\n",
    "\n",
    "    gbdt.fit(X_trainy, y_trainy)\n",
    "\n",
    "    # Step 2: Get predictions for all models on both training and test sets\n",
    "    gbdt_output_train = gbdt.predict(X_trainy)\n",
    "    gbdt_output_test = gbdt.predict(X_testy)\n",
    "\n",
    "    input_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    output_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "    input_scaler.fit(gbdt_output_train.reshape(-1, 1))\n",
    "    # output_scaler.fit(gbdt_output_train.reshape(-1, 1))\n",
    "    output_scaler.fit(y_trainy)\n",
    "\n",
    "    train_x_norm = input_scaler.transform(gbdt_output_train.reshape(-1, 1))\n",
    "    test_x_norm = input_scaler.transform(gbdt_output_test.reshape(-1, 1))\n",
    "    train_y_norm = output_scaler.transform(y_trainy)\n",
    "    test_y_norm = output_scaler.transform(y_testy)\n",
    "    \n",
    "    X_train, y_train = create_dataset(train_x_norm, train_y_norm, time_step)\n",
    "    X_test, y_test = create_dataset(test_x_norm, test_y_norm, time_step)   \n",
    "\n",
    "    # X_train_bilstm_gbdt = X_train_bilstm_gbdt.reshape(X_train_bilstm_gbdt.shape[0], time_step, 1)\n",
    "    # X_test_bilstm_gbdt = X_test_bilstm_gbdt.reshape(X_test_bilstm_gbdt.shape[0], time_step, 1)\n",
    "\n",
    "    model = Sequential([\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=True, input_shape=(time_step, num_feats))),\n",
    "      Dropout(dropout_rate),\n",
    "      Bidirectional(LSTM(int(units), activation='relu',return_sequences=False)),\n",
    "      Dropout(dropout_rate),\n",
    "      Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[r2_metric])\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=1, batch_size=int(batch_size), validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "    # Return validation loss as fitness\n",
    "    return history.history['val_loss'][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = [100, 1e-3, 0.1, 10]  # Lower bounds: [units, learning rate, dropout rate, batch size]\n",
    "ub = [300, 1e-2, 0.4, 300]  # Upper bounds: [units, learning rate, dropout rate, batch size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WOA:\n",
    "    def __init__(self, obj_func, n_whale, spiral_constant, n_iter,\n",
    "                lb, ub):\n",
    "        self.obj_func = obj_func\n",
    "        self.n_whale = n_whale\n",
    "        self.spiral_constant = spiral_constant\n",
    "        self.n_iter = n_iter\n",
    "        self.lb = lb\n",
    "        self.ub = ub\n",
    "        self.whale = {}\n",
    "        self.prey = {}\n",
    "\n",
    "    def init_whale(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),)) for i in range(self.n_whale)]\n",
    "        self.whale['position'] = np.array(tmp)\n",
    "        self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "\n",
    "    def init_prey(self):\n",
    "        tmp = [np.random.uniform(self.lb, self.ub, size=(len(self.lb),))]\n",
    "        self.prey['position'] = np.array(tmp)\n",
    "        # self.prey['fitness'] = self.obj_func(self.prey['position'])\n",
    "        # self.prey['fitness'] = [self.obj_func(self.prey['position'])] # modified this by adding [] \n",
    "        self.prey['fitness'] = np.array([self.obj_func(self.prey['position'])]) # modified\n",
    "\n",
    "    def update_prey(self):\n",
    "        # Get the minimum fitness from the whale population\n",
    "        min_fitness = min(self.whale['fitness'])  # Find the minimum fitness from whale's fitness array\n",
    "        if min_fitness < self.prey['fitness']:  # Compare with prey's fitness\n",
    "            min_index = np.argmin(self.whale['fitness'])  # Find the index of the minimum fitness\n",
    "            self.prey['position'] = self.whale['position'][min_index]  # Update prey's position\n",
    "            self.prey['fitness'] = min_fitness  # Update prey's fitness\n",
    "\n",
    "    def search(self, idx, A, C):\n",
    "            random_whale = self.whale['position'][np.random.randint(low=0, high=self.n_whale, size=len(idx[0]))]\n",
    "            \n",
    "            d = np.abs(C[..., np.newaxis] * random_whale - self.whale['position'][idx])\n",
    "            \n",
    "            self.whale['position'][idx] = np.clip(random_whale - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def encircle(self, idx, A, C):\n",
    "        d = np.abs(C[..., np.newaxis] * self.prey['position'] - self.whale['position'][idx])\n",
    "        \n",
    "        self.whale['position'][idx] = np.clip(self.prey['position'][0] - A[..., np.newaxis] * d, self.lb, self.ub)\n",
    "\n",
    "    def bubble_net(self, idx):\n",
    "        d_prime = np.abs(self.prey['position'] - self.whale['position'][idx])\n",
    "        l = np.random.uniform(-1, 1, size=len(idx[0]))\n",
    "        self.whale[\"position\"][idx] = np.clip(\n",
    "            d_prime * np.exp(self.spiral_constant * l)[..., np.newaxis] * np.cos(2 * np.pi * l)[..., np.newaxis]\n",
    "            + self.prey[\"position\"],\n",
    "            self.lb,\n",
    "            self.ub,\n",
    "        )\n",
    "\n",
    "    def optimize(self, a):\n",
    "\n",
    "        p = np.random.random(self.n_whale)\n",
    "        r1 = np.random.random(self.n_whale)\n",
    "        r2 = np.random.random(self.n_whale)\n",
    "        A = 2 * a * r1 - a\n",
    "        C = 2 * r2\n",
    "        search_idx = np.where((p < 0.5) & (abs(A) > 1))\n",
    "        encircle_idx = np.where((p < 0.5) & (abs(A) <= 1))\n",
    "        bubbleNet_idx = np.where(p >= 0.5)\n",
    "        self.search(search_idx, A[search_idx], C[search_idx])\n",
    "        self.encircle(encircle_idx, A[encircle_idx], C[encircle_idx])\n",
    "        self.bubble_net(bubbleNet_idx)\n",
    "        # self.whale['fitness'] = self.obj_func(self.whale['position'])\n",
    "        self.whale['fitness'] = np.array([self.obj_func(pos) for pos in self.whale['position']])\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.init_whale()\n",
    "        self.init_prey()\n",
    "        f_values = [self.prey['fitness'][0]]\n",
    "        # f_values = [self.prey['fitness']]\n",
    "        for n in range(self.n_iter):\n",
    "            #print(\"Iteration = \", n, \" f(x) = \", self.prey['fitness'][0])\n",
    "            a = 2 - n * (2 / self.n_iter)\n",
    "            self.optimize(a)\n",
    "            self.update_prey()\n",
    "            # f_values.append(self.prey['fitness'])\n",
    "            f_values.append(self.prey['fitness'][0])\n",
    "        optimal_x = self.prey['position']\n",
    "        return f_values, optimal_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278.98281234427316 0.006230520315698679 0.3946253240055062 40.69214988297695\n",
      "14/14 [==============================] - ETA: 0s - loss: 0.0980 - r2_metric: 0.2541WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x314e30fe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "14/14 [==============================] - 3s 130ms/step - loss: 0.0980 - r2_metric: 0.2541 - val_loss: 0.0218 - val_r2_metric: 0.8086\n",
      "225.56785685867914 0.0028156952892778976 0.327592091761468 43.98204333892108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - ETA: 0s - loss: 0.1224 - r2_metric: 0.0177 WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x314ef4040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "13/13 [==============================] - 3s 96ms/step - loss: 0.1224 - r2_metric: 0.0177 - val_loss: 0.0582 - val_r2_metric: 0.5183\n",
      "110.15232980637093 0.006755435114587305 0.13501346543980347 98.54162163918308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 89ms/step - loss: 0.1762 - r2_metric: -0.3373 - val_loss: 0.1091 - val_r2_metric: 0.0940\n",
      "277.6166301566202 0.009401298489357463 0.17695321858240426 107.82877163389296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 3s 224ms/step - loss: 0.1490 - r2_metric: -0.1188 - val_loss: 0.0968 - val_r2_metric: 0.2698\n",
      "120.52517581148112 0.0010331759238814458 0.14579353056114466 273.45595817859413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 228ms/step - loss: 0.1976 - r2_metric: -0.7524 - val_loss: 0.1369 - val_r2_metric: -0.1341\n",
      "150.52654481660574 0.001571439721448344 0.11592346605710971 107.84721643769282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 112ms/step - loss: 0.1716 - r2_metric: -0.2541 - val_loss: 0.1067 - val_r2_metric: 0.1592\n",
      "148.963258778321 0.0039713455886168925 0.33419853883902595 27.242044605121713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 2s 54ms/step - loss: 0.1080 - r2_metric: 0.1351 - val_loss: 0.0375 - val_r2_metric: 0.6885\n",
      "290.02222136453236 0.003732898488575458 0.3205233505346545 245.47585724175514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 444ms/step - loss: 0.1748 - r2_metric: -0.2401 - val_loss: 0.1217 - val_r2_metric: -0.0085\n",
      "161.93278160023695 0.007371995986537133 0.16582975592968502 285.50579846215663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 479ms/step - loss: 0.1924 - r2_metric: -0.4848 - val_loss: 0.1355 - val_r2_metric: -0.1228\n",
      "105.61357959695228 0.00876653209278563 0.1364165586477086 144.319057934066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 138ms/step - loss: 0.1818 - r2_metric: -0.4235 - val_loss: 0.1260 - val_r2_metric: -0.0438\n",
      "109.6996004361429 0.007165536987628463 0.34970304774700467 79.2878320486256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 31 calls to <function Model.make_train_function.<locals>.train_function at 0x369f01620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7/7 [==============================] - 2s 77ms/step - loss: 0.1599 - r2_metric: -0.2377 - val_loss: 0.1149 - val_r2_metric: 0.0445\n",
      "246.59811382026788 0.001269107623293137 0.2696903270119713 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 4s 56ms/step - loss: 0.0469 - r2_metric: 0.5908 - val_loss: 0.0156 - val_r2_metric: -12889.1953\n",
      "100.0 0.004625359843165637 0.33679091233343744 58.670309902559374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 139ms/step - loss: 0.1549 - r2_metric: -0.2071 - val_loss: 0.1099 - val_r2_metric: -1137777.1250\n",
      "300.0 0.01 0.4 70.99558106879448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 183ms/step - loss: 0.1296 - r2_metric: -0.0085 - val_loss: 0.0686 - val_r2_metric: 0.4355\n",
      "211.34471383371942 0.008937556021447952 0.19716100628846597 300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 501ms/step - loss: 0.2008 - r2_metric: -0.5440 - val_loss: 0.1408 - val_r2_metric: -0.1668\n",
      "108.88561326262091 0.006704437870378094 0.33437086208540256 64.68811252363382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 2s 63ms/step - loss: 0.1462 - r2_metric: -0.1270 - val_loss: 0.1037 - val_r2_metric: 0.1285\n",
      "256.02964685974814 0.002516640585839993 0.23394240850102876 300.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 645ms/step - loss: 0.1865 - r2_metric: -0.4268 - val_loss: 0.1140 - val_r2_metric: 0.0558\n",
      "103.73428093641412 0.006680244148323142 0.34734745091197594 71.38052631542658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 66ms/step - loss: 0.1487 - r2_metric: -0.1625 - val_loss: 0.1113 - val_r2_metric: 0.0724\n",
      "260.854747930763 0.01 0.3741628820887688 218.5946773605234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 3s 336ms/step - loss: 0.1710 - r2_metric: -0.2676 - val_loss: 0.1211 - val_r2_metric: -0.0036\n",
      "160.9333841713631 0.001 0.19945151542090023 10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 3s 34ms/step - loss: 0.0525 - r2_metric: 0.5321 - val_loss: 0.0170 - val_r2_metric: -15057.2627\n",
      "108.15822471449646 0.006561591221641405 0.2692446680687488 54.75600593376433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 59ms/step - loss: 0.1554 - r2_metric: -0.2031 - val_loss: 0.1025 - val_r2_metric: 0.1724\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m woa \u001b[38;5;241m=\u001b[39m WOA(obj_func\u001b[38;5;241m=\u001b[39mobj_func, n_whale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, spiral_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, lb\u001b[38;5;241m=\u001b[39mlb, ub\u001b[38;5;241m=\u001b[39mub)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run WOA optimization\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m f_values, optimal_hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[43mwoa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimal Hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, optimal_hyperparameters)\n",
      "Cell \u001b[0;32mIn[59], line 84\u001b[0m, in \u001b[0;36mWOA.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_prey()\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;66;03m# f_values.append(self.prey['fitness'])\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     f_values\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfitness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     85\u001b[0m optimal_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprey[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mposition\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f_values, optimal_x\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# Partial function to adapt objective function for WOA\n",
    "# obj_func = partial(lambda params: [evaluate_bilstm(param) for param in params])\n",
    "\n",
    "# obj_func = lambda params: evaluate_bilstm(params)\n",
    "\n",
    "obj_func = partial(lambda params: evaluate_bilstm(params))\n",
    "\n",
    "# Instantiate WOA\n",
    "woa = WOA(obj_func=obj_func, n_whale=10, spiral_constant=1, n_iter=10, lb=lb, ub=ub)\n",
    "\n",
    "# Run WOA optimization\n",
    "f_values, optimal_hyperparameters = woa.run()\n",
    "\n",
    "print(\"Optimal Hyperparameters:\", optimal_hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
